<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>求索</title>
  
  <subtitle>尔不必求记，却宜求个明白！</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.xiemx.com/"/>
  <updated>2020-02-25T04:12:56.079Z</updated>
  <id>https://www.xiemx.com/</id>
  
  <author>
    <name>Mingxu.xie</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>K8S initContainer</title>
    <link href="https://www.xiemx.com//2020/02/25/k8s-initcontainer/"/>
    <id>https://www.xiemx.com//2020/02/25/k8s-initcontainer/</id>
    <published>2020-02-25T03:52:00.000Z</published>
    <updated>2020-02-25T04:12:56.079Z</updated>
    
    <content type="html"><![CDATA[<p>k8s 可以通过init container来在容器启动之前执行一下初始化之类的操作，initContainers中的容器将按照顺序执行，并在上一个退出后执行下一个，所有容器安全运行结束后启动spec中的容器。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">xiemx</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">xiemx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">xiemx</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['sh',</span> <span class="string">'-c'</span><span class="string">,</span> <span class="string">'echo running &amp;&amp; sleep 60'</span><span class="string">]</span></span><br><span class="line"><span class="attr">  initContainers:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">init-1</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">["echo",</span> <span class="string">"init 1"</span><span class="string">]</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">init-2</span></span><br><span class="line"><span class="attr">    image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">    command:</span> <span class="string">['echo',</span> <span class="string">'init 2'</span><span class="string">]</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;k8s 可以通过init container来在容器启动之前执行一下初始化之类的操作，initContainers中的容器将按照顺序执行，并在上一个退出后执行下一个，所有容器安全运行结束后启动spec中的容器。&lt;/p&gt;
&lt;figure class=&quot;highlight ya
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="initContainer" scheme="https://www.xiemx.com/tags/initContainer/"/>
    
  </entry>
  
  <entry>
    <title>k8s pdb</title>
    <link href="https://www.xiemx.com//2020/02/24/k8s-pdb/"/>
    <id>https://www.xiemx.com//2020/02/24/k8s-pdb/</id>
    <published>2020-02-24T03:08:14.000Z</published>
    <updated>2020-02-24T03:29:21.006Z</updated>
    
    <content type="html"><![CDATA[<p>pdb 控制pod自愿中断时，最大可用和不可用的pod数量，可能会在node drain时阻断维护进程。</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">xiemx</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">xiemx</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">3</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">xiemx</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">xiemx</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["sleep",</span> <span class="string">"60"</span><span class="string">]</span></span><br><span class="line">        </span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">policy/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">PodDisruptionBudget</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">xiemx-PDB</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  maxUnavailable:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">xiemx</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">➜  pdb git:(master) ✗ k get pdb</span><br><span class="line">NAME        MIN AVAILABLE   MAX UNAVAILABLE   ALLOWED DISRUPTIONS   AGE</span><br><span class="line">xiemx-PDB   N/A             1                 0                     7s</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;pdb 控制pod自愿中断时，最大可用和不可用的pod数量，可能会在node drain时阻断维护进程。&lt;/p&gt;
&lt;figure class=&quot;highlight yaml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;l
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="pdb" scheme="https://www.xiemx.com/tags/pdb/"/>
    
  </entry>
  
  <entry>
    <title>K8S limitRange</title>
    <link href="https://www.xiemx.com//2020/02/22/k8s-limit-range/"/>
    <id>https://www.xiemx.com//2020/02/22/k8s-limit-range/</id>
    <published>2020-02-22T02:52:00.000Z</published>
    <updated>2020-02-25T02:41:17.787Z</updated>
    
    <content type="html"><![CDATA[<h4 id="ResourceQuota"><a href="#ResourceQuota" class="headerlink" title="ResourceQuota"></a>ResourceQuota</h4><p>resourceQuota 可以限制一个ns下可以创建的资源数量和资源的limit</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ResourceQuota</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">compute-resources</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  hard:</span></span><br><span class="line"><span class="attr">    pods:</span> <span class="string">"4"</span></span><br><span class="line">    <span class="string">requests.cpu:</span> <span class="string">"1"</span></span><br><span class="line">    <span class="string">requests.memory:</span> <span class="number">1</span><span class="string">Gi</span></span><br><span class="line">    <span class="string">limits.cpu:</span> <span class="string">"2"</span></span><br><span class="line">    <span class="string">limits.memory:</span> <span class="number">2</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure><hr><h4 id="LimitRange"><a href="#LimitRange" class="headerlink" title="LimitRange"></a>LimitRange</h4><p>k8s 使用limit range开控制一个命名空间下的不同type(pod, container)类型资源限制，参考下面</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Namespace</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-limit-range</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">LimitRange</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">limit-mem-cpu-per-container</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  limits:</span></span><br><span class="line"><span class="attr">  - max:</span></span><br><span class="line"><span class="attr">      cpu:</span> <span class="string">"800m"</span></span><br><span class="line"><span class="attr">      memory:</span> <span class="string">"1Gi"</span></span><br><span class="line"><span class="attr">    min:</span></span><br><span class="line"><span class="attr">      cpu:</span> <span class="string">"100m"</span></span><br><span class="line"><span class="attr">      memory:</span> <span class="string">"100Mi"</span></span><br><span class="line"><span class="attr">    default:</span></span><br><span class="line"><span class="attr">      cpu:</span> <span class="string">"700m"</span></span><br><span class="line"><span class="attr">      memory:</span> <span class="string">"900Mi"</span></span><br><span class="line"><span class="attr">    defaultRequest:</span></span><br><span class="line"><span class="attr">      cpu:</span> <span class="string">"110m"</span></span><br><span class="line"><span class="attr">      memory:</span> <span class="string">"200Mi"</span></span><br><span class="line"><span class="attr">    type:</span> <span class="string">Container</span></span><br><span class="line"></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Pod</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  containers:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">t01</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">[</span> <span class="string">"sleep"</span><span class="string">,</span> <span class="string">"60"</span><span class="string">]</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">t02</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">[</span> <span class="string">"sleep"</span><span class="string">,</span> <span class="string">"60"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        limits:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"200m"</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"300Mi"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">t03</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">[</span> <span class="string">"sleep"</span><span class="string">,</span> <span class="string">"60"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"300m"</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"400Mi"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">t04</span></span><br><span class="line"><span class="attr">      image:</span> <span class="string">busybox</span></span><br><span class="line"><span class="attr">      command:</span> <span class="string">[</span> <span class="string">"sleep"</span><span class="string">,</span> <span class="string">"60"</span><span class="string">]</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        limits:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"444m"</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"444Mi"</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          cpu:</span> <span class="string">"444m"</span></span><br><span class="line"><span class="attr">          memory:</span> <span class="string">"444Mi"</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br></pre></td><td class="code"><pre><span class="line">➜  limitRange git:(master) ✗ k get pod</span><br><span class="line">NAME   READY   STATUS    RESTARTS   AGE</span><br><span class="line">test   4/4     Running   0          20s</span><br><span class="line">➜  limitRange git:(master) ✗ k describe pod test</span><br><span class="line">Name:         test</span><br><span class="line">Namespace:    test-limit-range</span><br><span class="line">Priority:     0</span><br><span class="line">Node:         ip-10-200-1-57.ap-northeast-1.compute.internal/10.200.1.57</span><br><span class="line">Start Time:   Mon, 24 Feb 2020 10:17:19 +0800</span><br><span class="line">Labels:       &lt;none&gt;</span><br><span class="line">Annotations:  kubectl.kubernetes.io/last-applied-configuration:</span><br><span class="line">                &#123;"apiVersion":"v1","kind":"Pod","metadata":&#123;"annotations":&#123;&#125;,"name":"test","namespace":"test-limit-range"&#125;,"spec":&#123;"containers":[&#123;"command...</span><br><span class="line">              kubernetes.io/limit-ranger:</span><br><span class="line">                LimitRanger plugin set: cpu, memory request for container t01; cpu, memory limit for container t01; cpu, memory limit for container t03</span><br><span class="line">              kubernetes.io/psp: eks.privileged</span><br><span class="line">Status:       Running</span><br><span class="line">IP:           10.200.1.207</span><br><span class="line">IPs:          &lt;none&gt;</span><br><span class="line">Containers:</span><br><span class="line">  t01:</span><br><span class="line">    Container ID:  docker://b3d8927e0654e7be5f9d826ae14244c9c191d9a9bdb505a9a0b552f8502730e9</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://busybox@sha256:6915be4043561d64e0ab0f8f098dc2ac48e077fe23f488ac24b665166898115a</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sleep</span><br><span class="line">      60</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Mon, 24 Feb 2020 10:17:23 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Limits:</span><br><span class="line">      cpu:     700m</span><br><span class="line">      memory:  900Mi</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        110m</span><br><span class="line">      memory:     200Mi</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vjjds (ro)</span><br><span class="line">  t02:</span><br><span class="line">    Container ID:  docker://ca64d1db5597e14e4009c34febd4fd97e0a2858605dbcee5d2f4fa6e0d98342b</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://busybox@sha256:6915be4043561d64e0ab0f8f098dc2ac48e077fe23f488ac24b665166898115a</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sleep</span><br><span class="line">      60</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Mon, 24 Feb 2020 10:17:27 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Limits:</span><br><span class="line">      cpu:     200m</span><br><span class="line">      memory:  300Mi</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        200m</span><br><span class="line">      memory:     300Mi</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vjjds (ro)</span><br><span class="line">  t03:</span><br><span class="line">    Container ID:  docker://21891b99b6ebd54eadc4ceed63c451e0eb58392dec19679793a141fbadf22491</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://busybox@sha256:6915be4043561d64e0ab0f8f098dc2ac48e077fe23f488ac24b665166898115a</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sleep</span><br><span class="line">      60</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Mon, 24 Feb 2020 10:17:30 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Limits:</span><br><span class="line">      cpu:     700m</span><br><span class="line">      memory:  900Mi</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        300m</span><br><span class="line">      memory:     400Mi</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vjjds (ro)</span><br><span class="line">  t04:</span><br><span class="line">    Container ID:  docker://21e59b648db7aec5d345fc1d6b9998de3c924070c18fcc4e4627a45703401b9c</span><br><span class="line">    Image:         busybox</span><br><span class="line">    Image ID:      docker-pullable://busybox@sha256:6915be4043561d64e0ab0f8f098dc2ac48e077fe23f488ac24b665166898115a</span><br><span class="line">    Port:          &lt;none&gt;</span><br><span class="line">    Host Port:     &lt;none&gt;</span><br><span class="line">    Command:</span><br><span class="line">      sleep</span><br><span class="line">      60</span><br><span class="line">    State:          Running</span><br><span class="line">      Started:      Mon, 24 Feb 2020 10:17:33 +0800</span><br><span class="line">    Ready:          True</span><br><span class="line">    Restart Count:  0</span><br><span class="line">    Limits:</span><br><span class="line">      cpu:     444m</span><br><span class="line">      memory:  444Mi</span><br><span class="line">    Requests:</span><br><span class="line">      cpu:        444m</span><br><span class="line">      memory:     444Mi</span><br><span class="line">    Environment:  &lt;none&gt;</span><br><span class="line">    Mounts:</span><br><span class="line">      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vjjds (ro)</span><br><span class="line">Conditions:</span><br><span class="line">  Type              Status</span><br><span class="line">  Initialized       True</span><br><span class="line">  Ready             True</span><br><span class="line">  ContainersReady   True</span><br><span class="line">  PodScheduled      True</span><br><span class="line">Volumes:</span><br><span class="line">  default-token-vjjds:</span><br><span class="line">    Type:        Secret (a volume populated by a Secret)</span><br><span class="line">    SecretName:  default-token-vjjds</span><br><span class="line">    Optional:    false</span><br><span class="line">QoS Class:       Burstable</span><br><span class="line">Node-Selectors:  &lt;none&gt;</span><br><span class="line">Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s</span><br><span class="line">                 node.kubernetes.io/unreachable:NoExecute for 300s</span><br><span class="line">Events:</span><br><span class="line">  Type    Reason     Age   From                                                     Message</span><br><span class="line">  ----    ------     ----  ----                                                     -------</span><br><span class="line">  Normal  Scheduled  29s   default-scheduler                                        Successfully assigned test-limit-range/test to ip-10-200-1-57.ap-northeast-1.compute.internal</span><br><span class="line">  Normal  Pulling    28s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  pulling image "busybox"</span><br><span class="line">  Normal  Created    25s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Created container</span><br><span class="line">  Normal  Started    25s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Started container</span><br><span class="line">  Normal  Pulled     25s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Successfully pulled image "busybox"</span><br><span class="line">  Normal  Pulling    24s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  pulling image "busybox"</span><br><span class="line">  Normal  Pulling    21s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  pulling image "busybox"</span><br><span class="line">  Normal  Pulled     21s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Successfully pulled image "busybox"</span><br><span class="line">  Normal  Created    21s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Created container</span><br><span class="line">  Normal  Started    21s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Started container</span><br><span class="line">  Normal  Pulled     19s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Successfully pulled image "busybox"</span><br><span class="line">  Normal  Created    19s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Created container</span><br><span class="line">  Normal  Started    18s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Started container</span><br><span class="line">  Normal  Pulling    18s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  pulling image "busybox"</span><br><span class="line">  Normal  Pulled     16s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Successfully pulled image "busybox"</span><br><span class="line">  Normal  Created    16s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Created container</span><br><span class="line">  Normal  Started    15s   kubelet, ip-10-200-1-57.ap-northeast-1.compute.internal  Started container</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;ResourceQuota&quot;&gt;&lt;a href=&quot;#ResourceQuota&quot; class=&quot;headerlink&quot; title=&quot;ResourceQuota&quot;&gt;&lt;/a&gt;ResourceQuota&lt;/h4&gt;&lt;p&gt;resourceQuota 可以限制一个ns下可以创
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="limitRange" scheme="https://www.xiemx.com/tags/limitRange/"/>
    
      <category term="ResourceQuota" scheme="https://www.xiemx.com/tags/ResourceQuota/"/>
    
  </entry>
  
  <entry>
    <title>K8S HPA</title>
    <link href="https://www.xiemx.com//2020/01/25/k8s-hpa/"/>
    <id>https://www.xiemx.com//2020/01/25/k8s-hpa/</id>
    <published>2020-01-25T02:35:00.000Z</published>
    <updated>2020-02-25T02:35:58.721Z</updated>
    
    <content type="html"><![CDATA[<p>k8s hpa当前有3个版本分别支持, v1和v2/beta1版本只能使用CPU使用情况来进行扩容，v2beta2版本可以使用自定义指标来定义<br>使用v2beta2需要使用的metrics-server + prometheus, 使用另外的版本只需要metrics-server</p><p>metrics-server：<a href="https://github.com/kubernetes-sigs/metrics-server" target="_blank" rel="noopener">https://github.com/kubernetes-sigs/metrics-server</a><br>prometheus：<a href="https://github.com/coreos/prometheus-operator" target="_blank" rel="noopener">https://github.com/coreos/prometheus-operator</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">➜  metrics-server git:(master) ✗ k api-versions | grep autoscaling</span><br><span class="line">autoscaling/v1</span><br><span class="line">autoscaling/v2beta1</span><br><span class="line">autoscaling/v2beta2</span><br></pre></td></tr></table></figure><h4 id="explame"><a href="#explame" class="headerlink" title="explame"></a>explame</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    app:</span> <span class="string">test-hpa</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-hpa</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      app:</span> <span class="string">test-hpa</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        app:</span> <span class="string">test-hpa</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - args:</span></span><br><span class="line"><span class="bullet">        -</span> <span class="bullet">-cpus</span></span><br><span class="line"><span class="bullet">        -</span> <span class="string">"2"</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">vish/stress</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">test</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">0.01</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">25</span><span class="string">Mi</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">0.05</span></span><br><span class="line"><span class="attr">            memory:</span> <span class="number">60</span><span class="string">Mi</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">autoscaling/v2beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">HorizontalPodAutoscaler</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">test-hpa</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  scaleTargetRef:</span></span><br><span class="line"><span class="attr">    apiVersion:</span> <span class="string">apps/v1</span> </span><br><span class="line"><span class="attr">    kind:</span> <span class="string">Deployment</span> </span><br><span class="line"><span class="attr">    name:</span> <span class="string">test-hpa</span></span><br><span class="line"><span class="attr">  minReplicas:</span> <span class="number">1</span> </span><br><span class="line"><span class="attr">  maxReplicas:</span> <span class="number">10</span> </span><br><span class="line"><span class="attr">  metrics:</span></span><br><span class="line"><span class="attr">  - type:</span> <span class="string">Resource</span></span><br><span class="line"><span class="attr">    resource:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">cpu</span></span><br><span class="line"><span class="attr">      targetAverageUtilization:</span> <span class="number">10</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">➜  metrics-server git:(master) ✗ k get hpa</span><br><span class="line">NAME       REFERENCE             TARGETS    MINPODS   MAXPODS   REPLICAS   AGE</span><br><span class="line">test-hpa   Deployment/test-hpa   485%/10%   1         10        10         22h</span><br><span class="line">➜  metrics-server git:(master) ✗ kgp</span><br><span class="line">NAME                      READY   STATUS    RESTARTS   AGE</span><br><span class="line">test-hpa-6b9dd99d-22db4   1/1     Running   0          29m</span><br><span class="line">test-hpa-6b9dd99d-2dnt5   1/1     Running   0          30m</span><br><span class="line">test-hpa-6b9dd99d-68vnv   1/1     Running   0          29m</span><br><span class="line">test-hpa-6b9dd99d-8l59h   1/1     Running   0          29m</span><br><span class="line">test-hpa-6b9dd99d-hqbwf   1/1     Running   0          30m</span><br><span class="line">test-hpa-6b9dd99d-jx7s8   1/1     Running   0          30m</span><br><span class="line">test-hpa-6b9dd99d-qsw4n   1/1     Running   0          22h</span><br><span class="line">test-hpa-6b9dd99d-rvxw4   1/1     Running   0          29m</span><br><span class="line">test-hpa-6b9dd99d-sq4vz   1/1     Running   0          29m</span><br><span class="line">test-hpa-6b9dd99d-wppjm   1/1     Running   0          29m</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;k8s hpa当前有3个版本分别支持, v1和v2/beta1版本只能使用CPU使用情况来进行扩容，v2beta2版本可以使用自定义指标来定义&lt;br&gt;使用v2beta2需要使用的metrics-server + prometheus, 使用另外的版本只需要metrics-s
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="HPA" scheme="https://www.xiemx.com/tags/HPA/"/>
    
  </entry>
  
  <entry>
    <title>K8S 预选优选</title>
    <link href="https://www.xiemx.com//2020/01/25/k8s-predicate-and-priority/"/>
    <id>https://www.xiemx.com//2020/01/25/k8s-predicate-and-priority/</id>
    <published>2020-01-25T02:35:00.000Z</published>
    <updated>2020-02-25T04:03:36.147Z</updated>
    
    <content type="html"><![CDATA[<p><img src="/images/predicate.jpg" alt="predicate.jpg"></p><h4 id="predicate"><a href="#predicate" class="headerlink" title="predicate"></a>predicate</h4><hr><ul><li>NoDiskConflict：pod所需的卷是否和节点已存在的卷冲突</li><li>NoVolumeZoneConflict：检查给定的zone限制前提下，检查如果在此主机上部署Pod是否存在卷冲突。云厂商可用区限制。</li><li>PodFitsResources：检查节点是否有足够资源</li><li>PodFitsHostPorts：检查Pod容器所需的Port是否已被占用</li><li>HostName：检查节点是否满足PodSpec的NodeName字段中指定节点主机名，不满足节点的全部会被过滤掉。</li><li>MatchNodeSelector：检查节点标签（label）是否匹配Pod的nodeSelector属性要求</li><li>MaxEBSVolumeCount：确保已挂载的EBS存储卷不超过设置的最大值（默认值：39。Amazon推荐最大卷数量为40）</li><li>MaxGCEPDVolumeCount：确保已挂载的GCE存储卷不超过预设的最大值（默认值：16）</li><li>MaxAzureDiskVolumeCount : 确保已挂载的Azure存储卷不超过设置的最大值（默认值：16）</li><li>CheckNodeMemoryPressure : 判断节点是否已经进入到内存压力状态，如果是则只允许调度内存为0标记的Pod。检查Pod能否调度到内存有压力的节点上。如有节点存在内存压力， Guaranteed类型的Pod（例如，requests与limit均指定且值相等） 不能调度到节点上</li><li>CheckNodeDiskPressure : 判断节点是否已经进入到磁盘压力状态，如果是，则不调度新的Pod。</li><li>PodToleratesNodeTaints : 根据 taints 和 toleration 的关系判断Pod是否可以调度到节点上Pod是否满足节点容忍的一些条件。</li><li>MatchInterPodAffinity : 节点亲和性筛选。</li><li>GeneralPredicates：包含一些基本的筛选规则，主要考虑 Kubernetes 资源是否充足，比如 CPU 和 内存 是否足够，端口是否冲突、selector 是否匹配等：<ul><li>PodFitsResources：检查主机上的资源是否满足Pod的需求。资源的计算是根据主机上运行Pod请求的资源作为参考的，而不是以实际运行的资源数量</li><li>PodFitsHost：如果Pod指定了spec.NodeName，看节点的名字是否何它匹配，只有匹配的节点才能运行Pod</li><li>PodFitsHostPorts：检查Pod申请的主机端口是否已经被其他Pod占用，如果是，则不能调度</li><li>PodSelectorMatches：检查主机的标签是否满足Pod的 selector。包括NodeAffinity和nodeSelector中定义的标签。</li></ul></li></ul><h4 id="priority"><a href="#priority" class="headerlink" title="priority"></a>priority</h4><hr><ul><li>LeastRequestedPriority：节点的优先级就由节点空闲资源与节点总容量的比值，即由（总容量-节点上Pod的容量总和-新Pod的容量）/总容量）来决定。CPU和内存具有相同权重，资源空闲比越高的节点得分越高。需要注意的是，这个优先级函数起到了按照资源消耗来跨节点分配Pod的作用。详细的计算规则如下：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cpu((capacity – sum(requested)) * 10 / capacity) + memory((capacity – sum(requested)) * 10 / capacity) / 2</span><br></pre></td></tr></table></figure><ul><li><p>LeastRequestedPriority举例说明：例如CPU的可用资源为100，运行容器申请的资源为15，则cpu分值为8.5分，内存可用资源为100，运行容器申请资源为20，则内存分支为8分。则此评价规则在此节点的分数为(8.5 +8) / 2 = 8.25分。</p></li><li><p>BalancedResourceAllocation：CPU和内存使用率越接近的节点权重越高，该策略不能单独使用，必须和LeastRequestedPriority组合使用，尽量选择在部署Pod后各项资源更均衡的机器。如果请求的资源（CPU或者内存）大于节点的capacity，那么该节点永远不会被调度到。</p></li><li><p>BalancedResourceAllocation举例说明：该调度策略是出于平衡度的考虑，避免出现CPU，内存消耗不均匀的事情。例如某节点的CPU剩余资源还比较充裕，假如为100，申请10，则cpuFraction为0.1，而内存剩余资源不多，假如为20，申请10，则memoryFraction为0.5，这样由于CPU和内存使用不均衡，此节点的得分为10-abs ( 0.1 - 0.5 ) * 10 = 6 分。假如CPU和内存资源比较均衡，例如两者都为0.5，那么代入公式，则得分为10分。</p></li><li><p>InterPodAffinityPriority：通过迭代 weightedPodAffinityTerm 的元素计算和，并且如果对该节点满足相应的PodAffinityTerm，则将 “weight” 加到和中，具有最高和的节点是最优选的。 `</p></li><li><p>SelectorSpreadPriority：为了更好的容灾，对同属于一个service、replication controller或者replica的多个Pod副本，尽量调度到多个不同的节点上。如果指定了区域，调度器则会尽量把Pod分散在不同区域的不同节点上。当一个Pod的被调度时，会先查找Pod对于的service或者replication controller，然后查找service或replication controller中已存在的Pod，运行Pod越少的节点的得分越高。</p></li><li><p>SelectorSpreadPriority举例说明：这里主要针对多实例的情况下使用。例如，某一个服务，可能存在5个实例，例如当前节点已经分配了2个实例了，则本节点的得分为10*（（5-2）/ 5）=6分，而没有分配实例的节点，则得分为10 * （（5-0） / 5）=10分。没有分配实例的节点得分越高。</p></li><li><p>NodePreferAvoidPodsPriority（权重1W）：如果 节点的 Anotation 没有设置 key-value:scheduler. alpha.kubernetes.io/ preferAvoidPods = “…”，则节点对该 policy 的得分就是10分，加上权重10000，那么该node对该policy的得分至少10W分。如果Node的Anotation设置了，scheduler.alpha.kubernetes.io/preferAvoidPods = “…” ，如果该 pod 对应的 Controller 是 ReplicationController 或 ReplicaSet，则该 node 对该 policy 的得分就是0分。</p></li><li><p>TaintTolerationPriority : 使用 Pod 中 tolerationList 与 节点 Taint 进行匹配，配对成功的项越多，则得分越低。</p></li></ul><hr><p>搬运自：<a href="http://dockone.io/article/2885" target="_blank" rel="noopener">http://dockone.io/article/2885</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;img src=&quot;/images/predicate.jpg&quot; alt=&quot;predicate.jpg&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;predicate&quot;&gt;&lt;a href=&quot;#predicate&quot; class=&quot;headerlink&quot; title=&quot;predicate&quot;&gt;&lt;/
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>character-varying vs character vs text</title>
    <link href="https://www.xiemx.com//2020/01/22/character-varying/"/>
    <id>https://www.xiemx.com//2020/01/22/character-varying/</id>
    <published>2020-01-22T02:52:00.000Z</published>
    <updated>2020-02-24T01:53:57.621Z</updated>
    
    <content type="html"><![CDATA[<h4 id="字符串类型"><a href="#字符串类型" class="headerlink" title="字符串类型"></a>字符串类型</h4><table><thead><tr><th>名字</th><th>描述</th></tr></thead><tbody><tr><td>character varying(n), varchar(n)</td><td>变长，有长度限制</td></tr><tr><td>character(n), char(n)</td><td>定长，不足补空白</td></tr><tr><td>text</td><td>变长，无长度限制</td></tr></tbody></table><h4 id="类型区别"><a href="#类型区别" class="headerlink" title="类型区别"></a>类型区别</h4><ul><li><p>SQL定义了两种基本的字符类型：<code>character varying(n)</code> 和<code>character(n)</code>，这里的n是一个正整数。两种类型都可以存储最多n个字符的字符串。 试图存储更长的字符串到这些类型的字段里会产生一个错误， 除非超出长度的字符都是空白，这种情况下该字符串将被截断为最大长度。</p><ul><li><p><code>varchar(n)</code>和<code>char(n)</code>分别是<code>character varying(n)</code>和<code>character(n)</code>的别名。</p></li><li><p>如果要存储的字符串比声明的长度短，类型为<code>character</code>的数值将会用空白填满； 而类型为<code>character varying</code>的数值将只是存储短些的字符串。</p></li><li><p>如果我们明确地把一个数值转换成<code>character varying(n)</code>或<code>character(n)</code>，那么超长的数值将被截断成n 个字符，且不会抛出错误。这也是SQL标准的要求。</p></li><li><p>没有声明长度的<code>character</code>等于<code>character(1)</code>, 如果不带长度使用<code>character varying</code>， 那么该类型接受任何长度的字符串。后者是PostgreSQL的扩展。</p></li><li><p>character类型的数值物理上都用空白填充到指定的长度n， 并且以这种方式存储和显示。不过，在比较两个character 类型的值时，尾随的空白不需要理会。 在空白比较重要的排序规则中，这个行为会导致意想不到的结果， 比如<code>SELECT &#39;a &#39;::CHAR(2) collate &quot;C&quot; &lt; &#39;a\n&#39;::CHAR(2)</code>返回<code>true</code>。 在将<code>character</code>值转换成其它字符串类型的时候， 它后面的空白会被删除。请注意， 在<code>character varying</code>和<code>text</code>数值里， 结尾的空白是有语意的。 并且当使用模式匹配时，如LIKE，使用正则表达式。</p></li></ul></li></ul><h4 id="官方提示"><a href="#官方提示" class="headerlink" title="官方提示"></a>官方提示</h4><ul><li><p>三种类型<strong>没有性能差别</strong>，除了当使用填充空白类型时的增加存储空间和当存储长度约束的列时一些检查存入时长度的额外的CPU周期。 某些其它的数据库系统里，character(n) 有一定的性能优势，但在PostgreSQL里没有。 事实上，character(n)通常是这三个中最慢的， 因为额外存储成本。在大多数情况下，应该使用text 或character varying。</p></li><li><p>不管怎样，允许存储的最长字符串大概是<code>1GB</code> 。允许在数据类型声明中出现的n 的最大值比这还小。修改这个行为没有什么意义，因为在多字节编码下字符和字节的数目可能差别很大。 如果你想存储没有特定上限的长字符串，那么使用text 或没有长度声明的character varying，而不要选择一个任意长度限制。</p></li></ul><h4 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test1 (a <span class="built_in">character</span>(<span class="number">4</span>));</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test1 <span class="keyword">VALUES</span> (<span class="string">'ok'</span>);</span><br><span class="line"><span class="keyword">SELECT</span> a, <span class="keyword">char_length</span>(a) <span class="keyword">FROM</span> test1; <span class="comment">-- (1)</span></span><br><span class="line">  a   | char_length</span><br><span class="line"><span class="comment">------+-------------</span></span><br><span class="line"> ok   |           2</span><br><span class="line"></span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> test2 (b <span class="built_in">varchar</span>(<span class="number">5</span>));</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2 <span class="keyword">VALUES</span> (<span class="string">'ok'</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2 <span class="keyword">VALUES</span> (<span class="string">'good      '</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2 <span class="keyword">VALUES</span> (<span class="string">'too long'</span>);</span><br><span class="line">ERROR:  value too long for type character varying(5)</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> test2 <span class="keyword">VALUES</span> (<span class="string">'too long'</span>::<span class="built_in">varchar</span>(<span class="number">5</span>)); <span class="comment">-- 明确截断</span></span><br><span class="line"><span class="keyword">SELECT</span> b, <span class="keyword">char_length</span>(b) <span class="keyword">FROM</span> test2;</span><br><span class="line">   b   | char_length</span><br><span class="line"><span class="comment">-------+-------------</span></span><br><span class="line"> ok    |           2</span><br><span class="line"> good  |           5</span><br><span class="line"> too l |           5</span><br></pre></td></tr></table></figure><hr><p>postgresql字符串类型比较，参考：<br><a href="https://www.postgresql.org/docs/9.1/datatype-character.html" target="_blank" rel="noopener">https://www.postgresql.org/docs/9.1/datatype-character.html</a><br><a href="http://www.postgres.cn/docs/9.4/datatype-character.html" target="_blank" rel="noopener">http://www.postgres.cn/docs/9.4/datatype-character.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;字符串类型&quot;&gt;&lt;a href=&quot;#字符串类型&quot; class=&quot;headerlink&quot; title=&quot;字符串类型&quot;&gt;&lt;/a&gt;字符串类型&lt;/h4&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名字&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;
      
    
    </summary>
    
    
      <category term="database" scheme="https://www.xiemx.com/categories/database/"/>
    
    
      <category term="database" scheme="https://www.xiemx.com/tags/database/"/>
    
      <category term="postgresql" scheme="https://www.xiemx.com/tags/postgresql/"/>
    
  </entry>
  
  <entry>
    <title>K8S QOS</title>
    <link href="https://www.xiemx.com//2020/01/22/k8s-qos/"/>
    <id>https://www.xiemx.com//2020/01/22/k8s-qos/</id>
    <published>2020-01-22T02:52:00.000Z</published>
    <updated>2020-02-24T02:02:46.434Z</updated>
    
    <content type="html"><![CDATA[<p>对于一个 pod 来说，服务质量体现在两个具体的指标：CPU 和内存。当节点上内存资源紧张时，kubernetes 会根据预先设置的不同 QoS 类别进行相应处理。</p><ul><li><p>guaranteed （有保证的）</p></li><li><p>burstable （不稳定的）</p></li><li><p>Best-Effort （尽力而为）</p><h4 id="Guaranteed"><a href="#Guaranteed" class="headerlink" title="Guaranteed"></a>Guaranteed</h4><ul><li>Pod中的所有容器都且仅设置了 CPU 和内存的 limits</li><li>pod中的所有容器都设置了 CPU 和内存的 requests 和 limits ，且单个容器内的requests==limits（requests不等于0）</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#### set limit</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr"> name:</span> <span class="string">xiemx1</span></span><br><span class="line"><span class="attr">   resources:</span></span><br><span class="line"><span class="attr">     limits:</span></span><br><span class="line"><span class="attr">       cpu:</span> <span class="string">"10m"</span></span><br><span class="line"><span class="attr">       memory:</span> <span class="string">"1Gi"</span></span><br><span class="line"><span class="attr"> name:</span> <span class="string">xiemx2</span></span><br><span class="line"><span class="attr">   resources:</span></span><br><span class="line"><span class="attr">     limits:</span></span><br><span class="line"><span class="attr">       cpu:</span> <span class="string">"100m"</span></span><br><span class="line"><span class="attr">       memory:</span> <span class="string">"100Mi"</span></span><br><span class="line">       </span><br><span class="line"><span class="comment">#### request=limit</span></span><br><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr"> name:</span> <span class="string">xiemx1</span></span><br><span class="line"><span class="attr">   resources:</span></span><br><span class="line"><span class="attr">     limits:</span></span><br><span class="line"><span class="attr">       cpu:</span> <span class="string">"10m"</span></span><br><span class="line"><span class="attr">       memory:</span> <span class="string">"1Gi"</span></span><br><span class="line"><span class="attr">     requests:</span></span><br><span class="line"><span class="attr">       cpu:</span> <span class="string">"10m"</span></span><br><span class="line"><span class="attr">       memory:</span> <span class="string">"1Gi"</span></span><br><span class="line"></span><br><span class="line"><span class="attr"> name:</span> <span class="string">xiemx2</span></span><br><span class="line"><span class="attr">   resources:</span></span><br><span class="line"><span class="attr">     limits:</span></span><br><span class="line"><span class="attr">       cpu:</span> <span class="string">"100m"</span></span><br><span class="line"><span class="attr">       memory:</span> <span class="string">"100Mi"</span></span><br><span class="line"><span class="attr">     requests:</span></span><br><span class="line"><span class="attr">       cpu:</span> <span class="string">"100m"</span></span><br><span class="line"><span class="attr">       memory:</span> <span class="string">"100Mi"</span></span><br></pre></td></tr></table></figure><h4 id="Burstable"><a href="#Burstable" class="headerlink" title="Burstable"></a>Burstable</h4></li><li><p>pod中只要有一个容器的requests和limits的设置不相同</p></li><li><p>pod中只要有一个容器的cpu or memory 没有设置limits</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">xiemx1</span></span><br><span class="line"><span class="attr">    resources:</span></span><br><span class="line"><span class="attr">      limits:</span></span><br><span class="line"><span class="attr">        memory:</span> <span class="string">"1Gi"</span></span><br><span class="line"></span><br><span class="line"><span class="attr">  name:</span> <span class="string">xiemx2</span></span><br><span class="line"><span class="attr">    resources:</span></span><br><span class="line"><span class="attr">      limits:</span></span><br><span class="line"><span class="attr">        cpu:</span> <span class="string">"100m"</span></span><br></pre></td></tr></table></figure><h4 id="Best-Effort"><a href="#Best-Effort" class="headerlink" title="Best-Effort"></a>Best-Effort</h4><ul><li>Pod中所有容器的resources均未设置requests与limits</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">containers:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">xiemx1</span></span><br><span class="line"><span class="attr">    resources:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">xiemx2</span></span><br><span class="line"><span class="attr">    resources:</span></span><br></pre></td></tr></table></figure><h4 id="不同策略的QOS回收策略实现"><a href="#不同策略的QOS回收策略实现" class="headerlink" title="不同策略的QOS回收策略实现"></a>不同策略的QOS回收策略实现</h4><p>Kubernetes 通过cgroup给pod设置QoS级别，当资源不足时先kill优先级低的pod，通过OOM_ADJ参数计算分数值来实现，OOM分数值范围为0-1000。计算出来的OOM分数越高，表明该pod优先级就越低，当出现资源竞争时会越早被kill掉</p><ul><li>Guaranteed级别的 Pod，OOM_ADJ参数设置成了-998</li><li>Best-Effort级别的 Pod，OOM_ADJ参数设置成了1000</li><li>对于Burstable级别的 Pod，OOM_ADJ参数取值从2到999</li><li>kuberntes 保留资源，比如kubelet，docker，OOM_ADJ参数设置成了-999，表示不会被OOM kill掉</li></ul><h4 id="QoS-pods被kill掉场景与顺序"><a href="#QoS-pods被kill掉场景与顺序" class="headerlink" title="QoS pods被kill掉场景与顺序"></a>QoS pods被kill掉场景与顺序</h4><ul><li>Best-Effort pods：系统用完了全部内存时，该类型 pods 会最先被kill掉。</li><li>Burstable pods：系统用完了全部内存，且没有 Best-Effort 类型的容器可以被 kill 时，该类型的 pods 会被 kill 掉。</li><li>Guaranteed pods：系统用完了全部内存，且没有 Burstable 与 Best-Effort 类型的容器可以被 kill 时，该类型的 pods 会被 kill 掉。</li></ul><p>参考：<a href="https://www.qikqiak.com/post/kubernetes-qos-usage/" target="_blank" rel="noopener">https://www.qikqiak.com/post/kubernetes-qos-usage/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;对于一个 pod 来说，服务质量体现在两个具体的指标：CPU 和内存。当节点上内存资源紧张时，kubernetes 会根据预先设置的不同 QoS 类别进行相应处理。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;guaranteed （有保证的）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;bur
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
  </entry>
  
  <entry>
    <title>zombie/orphan process</title>
    <link href="https://www.xiemx.com//2020/01/22/zombie-and-orphan-process/"/>
    <id>https://www.xiemx.com//2020/01/22/zombie-and-orphan-process/</id>
    <published>2020-01-22T02:52:00.000Z</published>
    <updated>2020-01-22T03:02:33.828Z</updated>
    
    <content type="html"><![CDATA[<h3 id="zombie-process-orphan-process"><a href="#zombie-process-orphan-process" class="headerlink" title="zombie process / orphan process"></a>zombie process / orphan process</h3><p>父进程通过fork()函数来创建子进程。子进程会copy 当前父进程的状态和运行代码，独立运行，子进程和父进程的的运行和结束是一个异步的过程，fork出来之后运行的先后顺序也取决于系统的调度，不存在绝对的顺序。linux 为了进程退出能被正确回收，会维护一张进程的映射表，当进程结束时，系统会将进程的信息存储起来，等待父进程去处理回收子进程，处于退出状态且父进程没有调用wait()获取状态信息的进程就会陷入<code>Z</code> 状态，理论上所有的进程都会有一个短暂的<code>Z</code> 状态。</p><ul><li><p>orphan process：一个父进程退出，而子进程还在运行，这些子进程将成为孤儿进程，被init进程所收养，并由init进程对它们完成状态收集工作。</p></li><li><p>zombie process：进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。</p></li></ul><h4 id="如何处理僵尸进程-孤儿进程"><a href="#如何处理僵尸进程-孤儿进程" class="headerlink" title="如何处理僵尸进程/孤儿进程"></a>如何处理僵尸进程/孤儿进程</h4><ul><li>orphan process<br>  理论上孤儿进程不会对系统有影响，init 进程会接管成为父进程，负责进程回收，linux中也会有很多主动的操作来避免子进程被主动回收，比如说<code>nohup</code>、<code>disown</code> ，都是通过屏蔽信号来使子进程成为orphan process最终被init接收，实现终端关闭但是进程不退出</li><li>zombie process<br>  理论上zombie process是由于父进程不wait(), 可以直接干掉父进程，让init接手来处理</li></ul><h4 id="fork"><a href="#fork" class="headerlink" title="fork()"></a>fork()</h4><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">pid = fork()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> pid &gt; <span class="number">0</span> &#123; printf "this is father"&#125;</span><br><span class="line"><span class="keyword">if</span> pid = <span class="number">0</span> &#123; printf "this is child" &#125;</span><br><span class="line"><span class="keyword">if</span> pid &lt; <span class="number">0</span> &#123; printf "fork error" &#125;</span><br><span class="line"></span><br><span class="line">fork()后会<span class="keyword">copy</span>一个进程出来，fork后的代码会分布在子进程和当前进程中独立运行。也就是会有<span class="number">2</span>次输出。</span><br><span class="line">linux man page的说明：</span><br><span class="line"></span><br><span class="line">DESCRIPTION</span><br><span class="line">       The fork <span class="keyword">extension</span> adds three <span class="keyword">functions</span>, <span class="keyword">as</span> follows.</span><br><span class="line"></span><br><span class="line">       fork() This  <span class="keyword">function</span>  creates  a <span class="built_in">new</span> process. The <span class="keyword">return</span> <span class="keyword">value</span> <span class="keyword">is</span> the zero <span class="keyword">in</span> the child <span class="keyword">and</span> the process-id number <span class="keyword">of</span> the</span><br><span class="line">              child <span class="keyword">in</span> the parent, <span class="keyword">or</span> <span class="number">-1</span> upon  error.  <span class="keyword">In</span>  the  latter  <span class="keyword">case</span>,  ERRNO  indicates  the  problem.   <span class="keyword">In</span>  the  child,</span><br><span class="line">              PROCINFO["pid"] <span class="keyword">and</span> PROCINFO["ppid"] are updated <span class="keyword">to</span> reflect the correct <span class="keyword">values</span>.</span><br><span class="line"></span><br><span class="line">       waitpid()</span><br><span class="line">              This <span class="keyword">function</span> takes a <span class="type">numeric</span> argument, which <span class="keyword">is</span> the process-id <span class="keyword">to</span> wait <span class="keyword">for</span>. The <span class="keyword">return</span> <span class="keyword">value</span> <span class="keyword">is</span> that <span class="keyword">of</span> the wait-</span><br><span class="line">              pid(<span class="number">2</span>) <span class="keyword">system</span> <span class="keyword">call</span>.</span><br><span class="line"></span><br><span class="line">       wait() This <span class="keyword">function</span> waits <span class="keyword">for</span> the first child <span class="keyword">to</span> die.  The <span class="keyword">return</span> <span class="keyword">value</span> <span class="keyword">is</span> that <span class="keyword">of</span> the wait(<span class="number">2</span>) <span class="keyword">system</span> <span class="keyword">call</span>.</span><br></pre></td></tr></table></figure><p>参考：<a href="https://www.cnblogs.com/anker/p/3271773.html" target="_blank" rel="noopener">https://www.cnblogs.com/anker/p/3271773.html</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;zombie-process-orphan-process&quot;&gt;&lt;a href=&quot;#zombie-process-orphan-process&quot; class=&quot;headerlink&quot; title=&quot;zombie process / orphan process&quot;&gt;&lt;
      
    
    </summary>
    
    
      <category term="linux" scheme="https://www.xiemx.com/categories/linux/"/>
    
    
      <category term="linux" scheme="https://www.xiemx.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>k8s pod lifecycle</title>
    <link href="https://www.xiemx.com//2020/01/21/k8s-pod-lifecycle/"/>
    <id>https://www.xiemx.com//2020/01/21/k8s-pod-lifecycle/</id>
    <published>2020-01-21T09:08:14.000Z</published>
    <updated>2020-01-21T09:08:08.899Z</updated>
    
    <content type="html"><![CDATA[<h4 id="pod-phase"><a href="#pod-phase" class="headerlink" title="pod phase"></a>pod phase</h4><hr><ul><li>pending:  Pod 已被 Kubernetes 系统接受，但有一个或者多个容器镜像尚未创建。等待时间包括调度 Pod 的时间和通过网络下载镜像</li><li>running: 该 Pod 已经绑定到了一个节点上，Pod 中所有的容器都已被创建。至少有一个容器正在运行，或者正处于启动或重启状态。</li><li>successed: Pod 中的所有容器都被成功终止，并且不会再重启。</li><li>Failed: Pod 中的所有容器都已终止了，并且至少有一个容器是因为失败终止。也就是说，容器以非0状态退出或者被系统终止。</li><li>unkown: 某些原因无法取得 Pod 的状态，通常是因为与 Pod 所在主机通信失败。</li></ul><h4 id="探针"><a href="#探针" class="headerlink" title="探针"></a>探针</h4><hr><ul><li><code>livenessProbe</code>：指示容器是否正在运行。如果存活探测失败，则 kubelet 会杀死容器，并且容器将受到其 <a href="https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#restart-policy" target="_blank" rel="noopener">重启策略</a> 的影响。如果容器不提供存活探针，则默认状态为 <code>Success</code>。</li><li><code>readinessProbe</code>：指示容器是否准备好服务请求。如果就绪探测失败，端点控制器将从与 Pod 匹配的所有 Service 的端点中删除该 Pod 的 IP 地址。初始延迟之前的就绪状态默认为 <code>Failure</code>。如果容器不提供就绪探针，则默认状态为 <code>Success</code>。</li><li>探针支持的3种action事件<ul><li><a href="https://kubernetes.io/docs/resources-reference/v1.7/#execaction-v1-core" target="_blank" rel="noopener">ExecAction</a>：在容器内执行指定命令。如果命令退出时返回码为 0 则认为诊断成功。</li><li><a href="https://kubernetes.io/docs/resources-reference/v1.7/#tcpsocketaction-v1-core" target="_blank" rel="noopener">TCPSocketAction</a>：对指定端口上的容器的 IP 地址进行 TCP 检查。如果端口打开，则诊断被认为是成功的。</li><li><a href="https://kubernetes.io/docs/resources-reference/v1.7/#httpgetaction-v1-core" target="_blank" rel="noopener">HTTPGetAction</a>：对指定的端口和路径上的容器的 IP 地址执行 HTTP Get 请求。如果响应的状态码大于等于200 且小于 400，则诊断被认为是成功的。</li></ul></li></ul><h4 id="restart-policy"><a href="#restart-policy" class="headerlink" title="restart policy"></a>restart policy</h4><hr><ul><li>pod的spec中restartPolicy 有三种模式<pre><code>* Always* Never* OnFailure</code></pre></li><li>job 的spec中有2种<ul><li>OnFailure</li><li>Never</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;pod-phase&quot;&gt;&lt;a href=&quot;#pod-phase&quot; class=&quot;headerlink&quot; title=&quot;pod phase&quot;&gt;&lt;/a&gt;pod phase&lt;/h4&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;pending:  Pod 已被 Kubernetes 系统接
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="pod" scheme="https://www.xiemx.com/tags/pod/"/>
    
  </entry>
  
  <entry>
    <title>aws-vpc-cni</title>
    <link href="https://www.xiemx.com//2020/01/21/aws-vpc-cni/"/>
    <id>https://www.xiemx.com//2020/01/21/aws-vpc-cni/</id>
    <published>2020-01-21T09:05:04.000Z</published>
    <updated>2020-01-21T09:05:25.527Z</updated>
    
    <content type="html"><![CDATA[<h3 id="aws-vpc-cni"><a href="#aws-vpc-cni" class="headerlink" title="aws-vpc-cni"></a>aws-vpc-cni</h3><p>详细信息可以参考一下aws的提案</p><p>总结如下：</p><ol><li>AWS EKS运行在vpc中，因此所有节点能够运行的总pod数最终由vpc cidr中能够使用的ip地址数量来决定。</li><li>EKS node能够运行的pod数量，由node上的secendary ip数量决定，secendary ip是由eni的数量来决定的，可以理解不同的机型能够attach的eni数量决定了，node上能够运行多少pod。</li><li>pod使用cni来通讯，减少了中间网络层的封包/解包，网络性能上比较高。</li><li>aws-vpc-cni由两个部分组成<ol><li>Aws-vpc-cni 会在机器上嵌入一个进程<code>L-ipadm</code> 来管理pod的IP分配，eni的绑定和申请，ip pool的管理等等工作</li><li>cni plugin负责网络层的数据调度</li></ol></li></ol><hr><p>aws 提案：<a href="https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md" target="_blank" rel="noopener">https://github.com/aws/amazon-vpc-cni-k8s/blob/master/docs/cni-proposal.md</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;aws-vpc-cni&quot;&gt;&lt;a href=&quot;#aws-vpc-cni&quot; class=&quot;headerlink&quot; title=&quot;aws-vpc-cni&quot;&gt;&lt;/a&gt;aws-vpc-cni&lt;/h3&gt;&lt;p&gt;详细信息可以参考一下aws的提案&lt;/p&gt;
&lt;p&gt;总结如下：&lt;/p&gt;

      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="aws" scheme="https://www.xiemx.com/tags/aws/"/>
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="network" scheme="https://www.xiemx.com/tags/network/"/>
    
  </entry>
  
  <entry>
    <title>linux network namespace and bridge</title>
    <link href="https://www.xiemx.com//2020/01/21/linux-network-namespace/"/>
    <id>https://www.xiemx.com//2020/01/21/linux-network-namespace/</id>
    <published>2020-01-21T05:09:52.000Z</published>
    <updated>2020-01-21T08:56:26.914Z</updated>
    
    <content type="html"><![CDATA[<h3 id="linux-netns-和-bridge"><a href="#linux-netns-和-bridge" class="headerlink" title="linux netns 和 bridge"></a>linux netns 和 bridge</h3><h4 id="netns"><a href="#netns" class="headerlink" title="netns"></a>netns</h4><hr><p>最近在学习k8s网络，看到权威指南中有讲到基础网络的实现，故而搬运一下重新学习network namespace的隔离技术，默认binary是放在iproute2这个套件中的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-xenial:~$ apt-file search $(which ip)</span><br><span class="line">cups-ipp-utils: /usr/sbin/ippserver</span><br><span class="line">freeipa-client: /usr/sbin/ipa-certupdate</span><br><span class="line">freeipa-client: /usr/sbin/ipa-client-automount</span><br><span class="line">freeipa-client: /usr/sbin/ipa-client-install</span><br><span class="line">freeipa-client: /usr/sbin/ipa-getkeytab</span><br><span class="line">freeipa-client: /usr/sbin/ipa-join</span><br><span class="line">freeipa-client: /usr/sbin/ipa-rmkeytab</span><br><span class="line">iproute2: /sbin/ip</span><br></pre></td></tr></table></figure><p>默认情况下，使用 <code>ip netns</code> 是没有网络 namespace 的，所以 <code>ip netns ls</code> 命令看不到任何输出。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-xenial:~$ ip netns <span class="built_in">help</span></span><br><span class="line">Usage: ip netns list</span><br><span class="line">       ip netns add NAME</span><br><span class="line">       ip netns <span class="built_in">set</span> NAME NETNSID</span><br><span class="line">       ip [-all] netns delete [NAME]</span><br><span class="line">       ip netns identify [PID]</span><br><span class="line">       ip netns pids NAME</span><br><span class="line">       ip [-all] netns <span class="built_in">exec</span> [NAME] cmd ...</span><br><span class="line">       ip netns monitor</span><br><span class="line">       ip netns list-id</span><br></pre></td></tr></table></figure><p>新创建的 netns 会在<code>/var/run/netns/</code> 目录中生存对应名称的文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-xenial:~$ sudo ip netns add xiemx1</span><br><span class="line">vagrant@ubuntu-xenial:~$ sudo ip netns add xiemx2</span><br><span class="line">vagrant@ubuntu-xenial:~$ sudo ip netns ls</span><br><span class="line">xiemx2</span><br><span class="line">xiemx1</span><br><span class="line">vagrant@ubuntu-xenial:~$ ll /var/run/netns/</span><br><span class="line">total 0</span><br><span class="line">drwxr-xr-x  2 root root   80 Jan 21 03:19 ./</span><br><span class="line">drwxr-xr-x 28 root root 1140 Jan 21 03:19 ../</span><br><span class="line">-r--r--r--  1 root root    0 Jan 21 03:19 xiemx1</span><br><span class="line">-r--r--r--  1 root root    0 Jan 21 03:19 xiemx2</span><br></pre></td></tr></table></figure><p>由于netns 之间互相都是隔离的，因此要查看对应命名空间的网络设备、路由表就需要使用 <code>ip netns exec &lt;netns name&gt; bash</code>  开启子bash进入对应的命名空间，也可以直接执行命令</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-xenial:~$ sudo<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 02:97:71:8a:f0:d8 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.0.2.15/24 brd 10.0.2.255 scope global enp0s3</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::97:71ff:fe8a:f0d8/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: enp0s8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 08:00:27:f1:22:f6 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.110.120.65/24 brd 10.110.120.255 scope global enp0s8</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a00:27ff:fef1:22f6/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN<span class="built_in"> group </span>default</span><br><span class="line">    link/ether 02:42:da:5a:39:42 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line">vagrant@ubuntu-xenial:~$ sudo<span class="built_in"> ip </span>net exec xiemx1<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    </span><br><span class="line">vagrant@ubuntu-xenial:~$ sudo<span class="built_in"> ip </span>net exec xiemx2<span class="built_in"> ip </span>a</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br></pre></td></tr></table></figure><p>每个 namespace 在创建的时候会自动创建一个 <code>lo</code> ，默认时DOWN状态，如果需要启用记得UP一下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-xenial:~$ sudo ip net <span class="built_in">exec</span> xiemx1 ip a</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">vagrant@ubuntu-xenial:~$ sudo ip netns <span class="built_in">exec</span> xiemx1 ip link <span class="built_in">set</span> lo up</span><br><span class="line">vagrant@ubuntu-xenial:~$ sudo ip netns <span class="built_in">exec</span> xiemx1 ip a</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><h4 id="veth-pair"><a href="#veth-pair" class="headerlink" title="veth pair"></a>veth pair</h4><hr><p>netns 之间是相互隔离的，linux 提供了 <code>veth</code> 设备对来实现不同netns之间的往来通讯，veth 设备是成对出现的，类似于一根网线插到了两个隔离的ns之中，实现了两个隔离网络的互联。</p><p>我们可以使用 <code>ip link add &lt;name1&gt; type veth peer name &lt;name2&gt;</code> 来创建一对 veth pair 出来，需要记住的是 veth pair 无法单独存在，删除其中一个，另一个也会自动消失。</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">vagrant@ubuntu-xenial:~$ sudo<span class="built_in"> ip </span>netns exec xiemx1 bash</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>link <span class="builtin-name">add</span> xiemx-veth1<span class="built_in"> type </span>veth<span class="built_in"> peer </span>name xiemx-veth2</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: xiemx-veth2@xiemx-veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">5: xiemx-veth1@xiemx-veth2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 42:6a:cb:19:0d:2a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    </span><br><span class="line"><span class="comment">####如果对名称没有特别要求可以使用默认命令创建，会默认生存veth0/veth1 的设备对</span></span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>link <span class="builtin-name">add</span><span class="built_in"> type </span>veth</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: xiemx-veth2@xiemx-veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">5: xiemx-veth1@xiemx-veth2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 42:6a:cb:19:0d:2a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">6: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 3e:72:e3:48:25:69 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">7: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether ea:37:ea:92:a5:c5 brd ff:ff:ff:ff:ff:ff</span><br></pre></td></tr></table></figure><p>给这对 veth pair 配置上 ip 地址，并up</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>netns exec xiemx1 bash</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span><span class="builtin-name">add</span> <span class="builtin-name">add</span> 10.0.0.1/24 dev xiemx-veth1</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span><span class="builtin-name">add</span> <span class="builtin-name">add</span> 10.0.0.2/24 dev xiemx-veth2</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span><span class="builtin-name">add</span> show dev xiemx-veth1 up</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span><span class="builtin-name">add</span> show dev xiemx-veth2 up</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: xiemx-veth2@xiemx-veth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.0.0.2/24 scope global xiemx-veth2</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a476:6fff:fe47:e1f9/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: xiemx-veth1@xiemx-veth2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 42:6a:cb:19:0d:2a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.0.0.1/24 scope global xiemx-veth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::406a:cbff:fe19:d2a/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 3e:72:e3:48:25:69 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">7: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether ea:37:ea:92:a5:c5 brd ff:ff:ff:ff:ff:ff</span><br><span class="line"></span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>route</span><br><span class="line">10.0.0.0/24 dev xiemx-veth1  proto kernel  scope link  src 10.0.0.1</span><br><span class="line">10.0.0.0/24 dev xiemx-veth2  proto kernel  scope link  src 10.0.0.2</span><br></pre></td></tr></table></figure><p>目前所有的veth pair的两端都在xiemx1这个netns 中，现在移动设备的一段到xiemx2 这个netns中，实现网络互联</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>link <span class="builtin-name">set</span> xiemx-veth2 netns xiemx2</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: xiemx-veth1@if4: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state LOWERLAYERDOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 42:6a:cb:19:0d:2a brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.0.0.1/24 scope global xiemx-veth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::406a:cbff:fe19:d2a/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether 3e:72:e3:48:25:69 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">7: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether ea:37:ea:92:a5:c5 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>netns exec xiemx2<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">4: xiemx-veth2@if5: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>netns exec xiemx2 ifconfig xiemx-veth2 up</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>netns exec xiemx2<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">4: xiemx-veth2@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet6 fe80::a476:6fff:fe47:e1f9/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>netns exec xiemx2<span class="built_in"> ip </span><span class="builtin-name">add</span> <span class="builtin-name">add</span> 10.0.0.2/24 dev xiemx-veth2</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ip </span>netns exec xiemx2<span class="built_in"> ip </span>add</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN<span class="built_in"> group default </span>qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">4: xiemx-veth2@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP<span class="built_in"> group default </span>qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.0.0.2/24 scope global xiemx-veth2</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a476:6fff:fe47:e1f9/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">root@ubuntu-xenial:~#<span class="built_in"> ping </span>10.0.0.2</span><br><span class="line">PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes <span class="keyword">from</span> 10.0.0.2: <span class="attribute">icmp_seq</span>=1 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.083 ms</span><br><span class="line">64 bytes <span class="keyword">from</span> 10.0.0.2: <span class="attribute">icmp_seq</span>=2 <span class="attribute">ttl</span>=64 <span class="attribute">time</span>=0.046 ms</span><br><span class="line">^C</span><br><span class="line">--- 10.0.0.2<span class="built_in"> ping </span>statistics ---</span><br><span class="line">2 packets transmitted, 2 received, 0% packet loss, time 999ms</span><br><span class="line">rtt min/avg/max/mdev = 0.046/0.064/0.083/0.020 ms</span><br></pre></td></tr></table></figure><h4 id="bridge"><a href="#bridge" class="headerlink" title="bridge"></a>bridge</h4><hr><p>linux 内核支持网口桥接，但是和传统的硬件网桥不同的是，linux 中的网桥设备不仅仅是二层设备，只是对报文进行转发，由于Linux 主机上运行的上层应用有可能就是报文的终点，因此还要求网桥能够将保数据包传递给linux网络协议栈。</p><p>Docker bridge的网络就可以看成是通过bridge 来讲veth的设备对一端进行聚合，另一端放到容器的进程中，实现网络隔离和网络互联。再通过iptables的数据包转发功能来传递数据包，这里不讨论iptables层面的问题。</p><p>手动模拟一下大概如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##增加一个网桥（假设是docker bridge)</span></span></span><br><span class="line">root@ubuntu-xenial:~# ip netns exec xiemx1 bash</span><br><span class="line">root@ubuntu-xenial:~# brctl  show</span><br><span class="line">bridge namebridge idSTP enabledinterfaces</span><br><span class="line">root@ubuntu-xenial:~# brctl addbr xiemx-br</span><br><span class="line">root@ubuntu-xenial:~# brctl show</span><br><span class="line">bridge namebridge idSTP enabledinterfaces</span><br><span class="line">xiemx-br8000.000000000000no</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##将veth设备的一端绑定到网桥上，由于使用网桥进行通讯，所以veth设备在这里只需要当成二层设备来使用，不需要IP</span></span></span><br><span class="line">root@ubuntu-xenial:~# brctl addif xiemx-br veth0</span><br><span class="line">root@ubuntu-xenial:~# brctl show</span><br><span class="line">bridge namebridge idSTP enabledinterfaces</span><br><span class="line">xiemx-br8000.3e72e3482569noveth0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">##将veth的另一端移动到另一个netns中，可以理解为容器内的eth0</span></span></span><br><span class="line">root@ubuntu-xenial:~# ip link set veth1 netns xiemx2</span><br><span class="line">root@ubuntu-xenial:~# ip add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: xiemx-veth1@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 42:6a:cb:19:0d:2a brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.0.0.1/24 scope global xiemx-veth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::406a:cbff:fe19:d2a/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: veth0@if7: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop master xiemx-br state DOWN group default qlen 1000</span><br><span class="line">    link/ether 3e:72:e3:48:25:69 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">8: xiemx-br: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default qlen 1000</span><br><span class="line">    link/ether 3e:72:e3:48:25:69 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 11.0.0.1/24 brd 11.0.0.255 scope global xiemx-br</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line">root@ubuntu-xenial:~# ip netns exec xiemx2 bash</span><br><span class="line">root@ubuntu-xenial:~# ip add</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">4: xiemx-veth2@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.0.0.2/24 scope global xiemx-veth2</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a476:6fff:fe47:e1f9/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">7: veth1@if6: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000</span><br><span class="line">    link/ether ea:37:ea:92:a5:c5 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 给veth1 分配ip 地址，并开启设备</span></span></span><br><span class="line">root@ubuntu-xenial:~# ip add add 11.0.0.2/24 dev veth1</span><br><span class="line">root@ubuntu-xenial:~# ifconfig veth1 up</span><br><span class="line">root@ubuntu-xenial:~# ip add</span><br><span class="line">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">4: xiemx-veth2@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether a6:76:6f:47:e1:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.0.0.2/24 scope global xiemx-veth2</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::a476:6fff:fe47:e1f9/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">7: veth1@if6: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state LOWERLAYERDOWN group default qlen 1000</span><br><span class="line">    link/ether ea:37:ea:92:a5:c5 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 11.0.0.2/24 scope global veth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 给网桥分配IP，并开启veth0设备</span></span></span><br><span class="line">root@ubuntu-xenial:~# ip netns exec xiemx1 bash</span><br><span class="line">root@ubuntu-xenial:~# ifconfig xiemx-br 11.0.0.1/24</span><br><span class="line">root@ubuntu-xenial:~# ifconfig veth0 up</span><br><span class="line">root@ubuntu-xenial:~# ip add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: xiemx-veth1@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 42:6a:cb:19:0d:2a brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet 10.0.0.1/24 scope global xiemx-veth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::406a:cbff:fe19:d2a/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">6: veth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master xiemx-br state UP group default qlen 1000</span><br><span class="line">    link/ether 3e:72:e3:48:25:69 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet6 fe80::3c72:e3ff:fe48:2569/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">8: xiemx-br: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000</span><br><span class="line">    link/ether 3e:72:e3:48:25:69 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 11.0.0.1/24 brd 11.0.0.255 scope global xiemx-br</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::3c72:e3ff:fe48:2569/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="comment">## 测试网络联通</span></span></span><br><span class="line">root@ubuntu-xenial:~# ping 11.0.0.2</span><br><span class="line">PING 11.0.0.2 (11.0.0.2) 56(84) bytes of data.</span><br><span class="line">64 bytes from 11.0.0.2: icmp_seq=1 ttl=64 time=0.244 ms</span><br><span class="line">64 bytes from 11.0.0.2: icmp_seq=2 ttl=64 time=0.047 ms</span><br><span class="line">64 bytes from 11.0.0.2: icmp_seq=3 ttl=64 time=0.048 ms</span><br><span class="line">64 bytes from 11.0.0.2: icmp_seq=4 ttl=64 time=0.047 ms</span><br><span class="line">64 bytes from 11.0.0.2: icmp_seq=5 ttl=64 time=0.051 ms</span><br><span class="line">^C</span><br><span class="line">--- 11.0.0.2 ping statistics ---</span><br><span class="line">5 packets transmitted, 5 received, 0% packet loss, time 4005ms</span><br><span class="line">rtt min/avg/max/mdev = 0.047/0.087/0.244/0.078 ms</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;linux-netns-和-bridge&quot;&gt;&lt;a href=&quot;#linux-netns-和-bridge&quot; class=&quot;headerlink&quot; title=&quot;linux netns 和 bridge&quot;&gt;&lt;/a&gt;linux netns 和 bridge&lt;/h3&gt;&lt;
      
    
    </summary>
    
    
      <category term="linux" scheme="https://www.xiemx.com/categories/linux/"/>
    
    
      <category term="network" scheme="https://www.xiemx.com/tags/network/"/>
    
      <category term="linux" scheme="https://www.xiemx.com/tags/linux/"/>
    
      <category term="docker" scheme="https://www.xiemx.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>k8s Flannel</title>
    <link href="https://www.xiemx.com//2020/01/21/k8s-fannel/"/>
    <id>https://www.xiemx.com//2020/01/21/k8s-fannel/</id>
    <published>2020-01-21T02:01:04.000Z</published>
    <updated>2020-01-21T09:03:57.654Z</updated>
    
    <content type="html"><![CDATA[<h4 id="K8S-Flannel"><a href="#K8S-Flannel" class="headerlink" title="K8S Flannel"></a>K8S Flannel</h4><p>Flannel 的网络个人理解为，flannel接管了所有k8s node节点上的docker 网络的配置，在docker 启动之前，flannel通过在etcd 中共享 flannel的subnet等网段信息来给每个node的docker 预设网络信息，以及分配子网段和bridge地址，以保证在分布式的环境下不会出现网络冲突，因此flannel 可以看作是侵入了docker层面，在底层系统启动container的时候就处理了网络相关，构建了一个大内网。在宿主机的docker控制了所有节点的bridge，并更新所有node上的网段信息的对应路由表，在同一个大网段内，来保证网络连通性。</p><hr><p>以下配置参考信息转自：<a href="https://jimmysong.io/kubernetes-handbook/concepts/flannel.html" target="_blank" rel="noopener">https://jimmysong.io/kubernetes-handbook/concepts/flannel.html</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># kubectl get nodes -o wide</span></span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION   EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION               CONTAINER-RUNTIME</span><br><span class="line">node1     Ready     &lt;none&gt;    2d        v1.9.1    &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-693.11.6.el7.x86_64   docker://1.12.6</span><br><span class="line">node2     Ready     &lt;none&gt;    2d        v1.9.1    &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-693.11.6.el7.x86_64   docker://1.12.6</span><br><span class="line">node3     Ready     &lt;none&gt;    2d        v1.9.1    &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-693.11.6.el7.x86_64   docker://1.12.6</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>当前Kubernetes集群中运行的所有Pod信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># kubectl get pods --all-namespaces -o wide</span></span><br><span class="line">NAMESPACE     NAME                                              READY     STATUS    RESTARTS   AGE       IP            NODE</span><br><span class="line">kube-system   coredns-5984fb8cbb-sjqv9                          1/1       Running   0          1h        172.33.68.2   node1</span><br><span class="line">kube-system   coredns-5984fb8cbb-tkfrc                          1/1       Running   1          1h        172.33.96.3   node3</span><br><span class="line">kube-system   heapster-v1.5.0-684c7f9488-z6sdz                  4/4       Running   0          1h        172.33.31.3   node2</span><br><span class="line">kube-system   kubernetes-dashboard-6b66b8b96c-mnm2c             1/1       Running   0          1h        172.33.31.2   node2</span><br><span class="line">kube-system   monitoring-influxdb-grafana-v4-54b7854697-tw9cd   2/2       Running   2          1h        172.33.96.2   node3</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>当前etcd中的注册的宿主机的pod地址网段信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># etcdctl ls /kube-centos/network/subnets</span></span><br><span class="line">/kube-centos/network/subnets/172.33.68.0-24</span><br><span class="line">/kube-centos/network/subnets/172.33.31.0-24</span><br><span class="line">/kube-centos/network/subnets/172.33.96.0-24</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>而每个node上的Pod子网是根据我们在安装flannel时配置来划分的，在etcd中查看该配置：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># etcdctl get /kube-centos/network/config</span></span><br><span class="line">&#123;<span class="string">"Network"</span>:<span class="string">"172.33.0.0/16"</span>,<span class="string">"SubnetLen"</span>:24,<span class="string">"Backend"</span>:&#123;<span class="string">"Type"</span>:<span class="string">"host-gw"</span>&#125;&#125;</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>我们知道Kubernetes集群内部存在三类IP，分别是：</p><ul><li>Node IP：宿主机的IP地址</li><li>Pod IP：使用网络插件创建的IP（如flannel），使跨主机的Pod可以互通</li><li>Cluster IP：虚拟IP，通过iptables规则访问服务</li></ul><p>在安装node节点的时候，节点上的进程是按照flannel -&gt; docker -&gt; kubelet -&gt; kube-proxy的顺序启动的，我们下面也会按照该顺序来讲解，flannel的网络划分和如何与docker交互，如何通过iptables访问service。</p><h3 id="Flannel"><a href="#Flannel" class="headerlink" title="Flannel"></a>Flannel</h3><p>Flannel是作为一个二进制文件的方式部署在每个node上，主要实现两个功能：</p><ul><li>为每个node分配subnet，容器将自动从该子网中获取IP地址</li><li>当有node加入到网络中时，为每个node增加路由配置</li></ul><p>下面是使用<code>host-gw</code> backend的flannel网络架构图：</p><p><a href="https://jimmysong.io/kubernetes-handbook/images/flannel-networking.png" target="_blank" rel="noopener"><img src="../images/flannel-networking-20200121145349208.png" alt="flannel网络架构（图片来自openshift）"></a>图片 - flannel网络架构（图片来自openshift）。以上IP非本示例中的IP。</p><p>Node1上的flannel配置如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># cat /usr/lib/systemd/system/flanneld.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Flanneld overlay address etcd agent</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line">After=etcd.service</span><br><span class="line">Before=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">EnvironmentFile=/etc/sysconfig/flanneld</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/docker-network</span><br><span class="line">ExecStart=/usr/bin/flanneld-start <span class="variable">$FLANNEL_OPTIONS</span></span><br><span class="line">ExecStartPost=/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">RequiredBy=docker.service</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>其中有两个环境变量文件的配置如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># cat /etc/sysconfig/flanneld</span></span><br><span class="line"><span class="comment"># Flanneld configuration options</span></span><br><span class="line">FLANNEL_ETCD_ENDPOINTS=<span class="string">"http://172.17.8.101:2379"</span></span><br><span class="line">FLANNEL_ETCD_PREFIX=<span class="string">"/kube-centos/network"</span></span><br><span class="line">FLANNEL_OPTIONS=<span class="string">"-iface=eth2"</span></span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>上面的配置文件仅供flanneld使用。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># cat /etc/sysconfig/docker-network</span></span><br><span class="line"><span class="comment"># /etc/sysconfig/docker-network</span></span><br><span class="line">DOCKER_NETWORK_OPTIONS=</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>还有一个<code>ExecStartPost=/usr/libexec/flannel/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/docker</code>，其中的<code>/usr/libexec/flannel/mk-docker-opts.sh</code>脚本是在flanneld启动后运行，将会生成两个环境变量配置文件：</p><ul><li>/run/flannel/docker</li><li>/run/flannel/subnet.env</li></ul><p>我们再来看下<code>/run/flannel/docker</code>的配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># cat /run/flannel/docker</span></span><br><span class="line">DOCKER_OPT_BIP=<span class="string">"--bip=172.33.68.1/24"</span></span><br><span class="line">DOCKER_OPT_IPMASQ=<span class="string">"--ip-masq=true"</span></span><br><span class="line">DOCKER_OPT_MTU=<span class="string">"--mtu=1500"</span></span><br><span class="line">DOCKER_NETWORK_OPTIONS=<span class="string">" --bip=172.33.68.1/24 --ip-masq=true --mtu=1500"</span></span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>如果你使用<code>systemctl</code>命令先启动flannel后启动docker的话，docker将会读取以上环境变量。</p><p>我们再来看下<code>/run/flannel/subnet.env</code>的配置。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># cat /run/flannel/subnet.env</span></span><br><span class="line">FLANNEL_NETWORK=172.33.0.0/16</span><br><span class="line">FLANNEL_SUBNET=172.33.68.1/24</span><br><span class="line">FLANNEL_MTU=1500</span><br><span class="line">FLANNEL_IPMASQ=<span class="literal">false</span></span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>以上环境变量是flannel向etcd中注册的。</p><h3 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h3><p>Node1的docker配置如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># cat /usr/lib/systemd/system/docker.service</span></span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=http://docs.docker.com</span><br><span class="line">After=network.target rhel-push-plugin.socket registries.service</span><br><span class="line">Wants=docker-storage-setup.service</span><br><span class="line">Requires=docker-cleanup.timer</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">NotifyAccess=all</span><br><span class="line">EnvironmentFile=-/run/containers/registries.conf</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/docker</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/docker-storage</span><br><span class="line">EnvironmentFile=-/etc/sysconfig/docker-network</span><br><span class="line">Environment=GOTRACEBACK=crash</span><br><span class="line">Environment=DOCKER_HTTP_HOST_COMPAT=1</span><br><span class="line">Environment=PATH=/usr/libexec/docker:/usr/bin:/usr/sbin</span><br><span class="line">ExecStart=/usr/bin/dockerd-current \</span><br><span class="line">          --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current \</span><br><span class="line">          --default-runtime=docker-runc \</span><br><span class="line">          --<span class="built_in">exec</span>-opt native.cgroupdriver=systemd \</span><br><span class="line">          --userland-proxy-path=/usr/libexec/docker/docker-proxy-current \</span><br><span class="line">          <span class="variable">$OPTIONS</span> \</span><br><span class="line">          <span class="variable">$DOCKER_STORAGE_OPTIONS</span> \</span><br><span class="line">          <span class="variable">$DOCKER_NETWORK_OPTIONS</span> \</span><br><span class="line">          <span class="variable">$ADD_REGISTRY</span> \</span><br><span class="line">          <span class="variable">$BLOCK_REGISTRY</span> \</span><br><span class="line">          <span class="variable">$INSECURE_REGISTRY</span>\</span><br><span class="line">          <span class="variable">$REGISTRIES</span></span><br><span class="line">ExecReload=/bin/<span class="built_in">kill</span> -s HUP <span class="variable">$MAINPID</span></span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">LimitNPROC=1048576</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">TimeoutStartSec=0</span><br><span class="line">Restart=on-abnormal</span><br><span class="line">MountFlags=slave</span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>查看Node1上的docker启动参数：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># systemctl status -l docker</span></span><br><span class="line">● docker.service - Docker Application Container Engine</span><br><span class="line">   Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled)</span><br><span class="line">  Drop-In: /usr/lib/systemd/system/docker.service.d</span><br><span class="line">           └─flannel.conf</span><br><span class="line">   Active: active (running) since Fri 2018-02-02 22:52:43 CST; 2h 28min ago</span><br><span class="line">     Docs: http://docs.docker.com</span><br><span class="line"> Main PID: 4334 (dockerd-current)</span><br><span class="line">   CGroup: /system.slice/docker.service</span><br><span class="line">           ‣ 4334 /usr/bin/dockerd-current --add-runtime docker-runc=/usr/libexec/docker/docker-runc-current --default-runtime=docker-runc --<span class="built_in">exec</span>-opt native.cgroupdriver=systemd --userland-proxy-path=/usr/libexec/docker/docker-proxy-current --selinux-enabled --<span class="built_in">log</span>-driver=journald --signature-verification=<span class="literal">false</span> --bip=172.33.68.1/24 --ip-masq=<span class="literal">true</span> --mtu=1500</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>我们可以看到在docker在启动时有如下参数：<code>--bip=172.33.68.1/24 --ip-masq=true --mtu=1500</code>。上述参数flannel启动时运行的脚本生成的，通过环境变量传递过来的。</p><p>我们查看下node1宿主机上的网络接口：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># ip addr</span></span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1</span><br><span class="line">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1/8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1/128 scope host</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link/ether 52:54:00:00:57:32 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 10.0.2.15/24 brd 10.0.2.255 scope global dynamic eth0</span><br><span class="line">       valid_lft 85095sec preferred_lft 85095sec</span><br><span class="line">    inet6 fe80::5054:ff:fe00:5732/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link/ether 08:00:27:7b:0f:b1 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.8.101/24 brd 172.17.8.255 scope global eth1</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">4: eth2: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000</span><br><span class="line">    link/ether 08:00:27:ef:25:06 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.30.113.231/21 brd 172.30.119.255 scope global dynamic eth2</span><br><span class="line">       valid_lft 85096sec preferred_lft 85096sec</span><br><span class="line">    inet6 fe80::a00:27ff:feef:2506/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">5: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP</span><br><span class="line">    link/ether 02:42:d0:ae:80:ea brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.33.68.1/24 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:d0ff:feae:80ea/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">7: veth295bef2@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP</span><br><span class="line">    link/ether 6a:72:d7:9f:29:19 brd ff:ff:ff:ff:ff:ff link-netnsid 0</span><br><span class="line">    inet6 fe80::6872:d7ff:fe9f:2919/64 scope link</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>我们分类来解释下该虚拟机中的网络接口。</p><ul><li><p>lo：回环网络，127.0.0.1</p></li><li><p>eth0：NAT网络，虚拟机创建时自动分配，仅可以在几台虚拟机之间访问</p></li><li><p>eth1：bridge网络，使用vagrant分配给虚拟机的地址，虚拟机之间和本地电脑都可以访问</p></li><li><p>eth2：bridge网络，使用DHCP分配，用于访问互联网的网卡</p></li><li><p>docker0：bridge网络，docker默认使用的网卡，作为该节点上所有容器的虚拟交换机</p></li><li><p>veth295bef2@if6：veth pair，连接docker0和Pod中的容器。veth pair可以理解为使用网线连接好的两个接口，把两个端口放到两个namespace中，那么这两个namespace就能打通。</p></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># docker network ls</span></span><br><span class="line">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class="line">940bb75e653b        bridge              bridge              <span class="built_in">local</span></span><br><span class="line">d94c046e105d        host                host                <span class="built_in">local</span></span><br><span class="line">2db7597fd546        none                null                <span class="built_in">local</span></span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>再检查下bridge网络<code>940bb75e653b</code>的信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># docker network inspect 940bb75e653b</span></span><br><span class="line">[</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="string">"Name"</span>: <span class="string">"bridge"</span>,</span><br><span class="line">        <span class="string">"Id"</span>: <span class="string">"940bb75e653bfa10dab4cce8813c2b3ce17501e4e4935f7dc13805a61b732d2c"</span>,</span><br><span class="line">        <span class="string">"Scope"</span>: <span class="string">"local"</span>,</span><br><span class="line">        <span class="string">"Driver"</span>: <span class="string">"bridge"</span>,</span><br><span class="line">        <span class="string">"EnableIPv6"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"IPAM"</span>: &#123;</span><br><span class="line">            <span class="string">"Driver"</span>: <span class="string">"default"</span>,</span><br><span class="line">            <span class="string">"Options"</span>: null,</span><br><span class="line">            <span class="string">"Config"</span>: [</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">"Subnet"</span>: <span class="string">"172.33.68.1/24"</span>,</span><br><span class="line">                    <span class="string">"Gateway"</span>: <span class="string">"172.33.68.1"</span></span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"Internal"</span>: <span class="literal">false</span>,</span><br><span class="line">        <span class="string">"Containers"</span>: &#123;</span><br><span class="line">            <span class="string">"944d4aa660e30e1be9a18d30c9dcfa3b0504d1e5dbd00f3004b76582f1c9a85b"</span>: &#123;</span><br><span class="line">                <span class="string">"Name"</span>: <span class="string">"k8s_POD_coredns-5984fb8cbb-sjqv9_kube-system_c5a2e959-082a-11e8-b4cd-525400005732_0"</span>,</span><br><span class="line">                <span class="string">"EndpointID"</span>: <span class="string">"7397d7282e464fc4ec5756d6b328df889cdf46134dbbe3753517e175d3844a85"</span>,</span><br><span class="line">                <span class="string">"MacAddress"</span>: <span class="string">"02:42:ac:21:44:02"</span>,</span><br><span class="line">                <span class="string">"IPv4Address"</span>: <span class="string">"172.33.68.2/24"</span>,</span><br><span class="line">                <span class="string">"IPv6Address"</span>: <span class="string">""</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"Options"</span>: &#123;</span><br><span class="line">            <span class="string">"com.docker.network.bridge.default_bridge"</span>: <span class="string">"true"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.enable_icc"</span>: <span class="string">"true"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.enable_ip_masquerade"</span>: <span class="string">"true"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.host_binding_ipv4"</span>: <span class="string">"0.0.0.0"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.bridge.name"</span>: <span class="string">"docker0"</span>,</span><br><span class="line">            <span class="string">"com.docker.network.driver.mtu"</span>: <span class="string">"1500"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="string">"Labels"</span>: &#123;&#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>我们可以看到该网络中的<code>Config</code>与docker的启动配置相符。</p><p>Node1上运行的容器：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># docker ps</span></span><br><span class="line">CONTAINER ID        IMAGE                                                                                               COMMAND                  CREATED             STATUS              PORTS               NAMES</span><br><span class="line">a37407a234dd        docker.io/coredns/coredns@sha256:adf2e5b4504ef9ffa43f16010bd064273338759e92f6f616dd159115748799bc   <span class="string">"/coredns -conf /etc/"</span>   About an hour ago   Up About an hour                        k8s_coredns_coredns-5984fb8cbb-sjqv9_kube-system_c5a2e959-082a-11e8-b4cd-525400005732_0</span><br><span class="line">944d4aa660e3        docker.io/openshift/origin-pod                                                                      <span class="string">"/usr/bin/pod"</span>           About an hour ago   Up About an hour                        k8s_POD_coredns-5984fb8cbb-sjqv9_kube-system_c5a2e959-082a-11e8-b4cd-525400005732_0</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>我们可以看到当前已经有2个容器在运行。</p><p>Node1上的路由信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># route -n</span></span><br><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         10.0.2.2        0.0.0.0         UG    100    0        0 eth0</span><br><span class="line">0.0.0.0         172.30.116.1    0.0.0.0         UG    101    0        0 eth2</span><br><span class="line">10.0.2.0        0.0.0.0         255.255.255.0   U     100    0        0 eth0</span><br><span class="line">172.17.8.0      0.0.0.0         255.255.255.0   U     100    0        0 eth1</span><br><span class="line">172.30.112.0    0.0.0.0         255.255.248.0   U     100    0        0 eth2</span><br><span class="line">172.33.68.0     0.0.0.0         255.255.255.0   U     0      0        0 docker0</span><br><span class="line">172.33.96.0     172.3.65   255.255.255.0   UG    0      0        0 eth2</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>以上路由信息是由flannel添加的，当有新的节点加入到Kubernetes集群中后，每个节点上的路由表都将增加。</p><p>我们在node上来<code>traceroute</code>下node3上的<code>coredns-5984fb8cbb-tkfrc</code>容器，其IP地址是<code>172.33.96.3</code>，看看其路由信息。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># traceroute 172.33.96.3</span></span><br><span class="line">traceroute to 172.33.96.3 (172.33.96.3), 30 hops max, 60 byte packets</span><br><span class="line"> 1  172.30.118.65 (172.30.118.65)  0.518 ms  0.367 ms  0.398 ms</span><br><span class="line"> 2  172.33.96.3 (172.33.96.3)  0.451 ms  0.352 ms  0.223 ms</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure><p>我们看到路由直接经过node3的公网IP后就到达了node3节点上的Pod。</p><p>Node1的iptables信息：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment"># iptables -L</span></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">KUBE-FIREWALL  all  --  anywhere             anywhere</span><br><span class="line">KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */</span><br><span class="line"></span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">KUBE-FORWARD  all  --  anywhere             anywhere             /* kubernetes forward rules */</span><br><span class="line">DOCKER-ISOLATION  all  --  anywhere             anywhere</span><br><span class="line">DOCKER     all  --  anywhere             anywhere</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere</span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">KUBE-FIREWALL  all  --  anywhere             anywhere</span><br><span class="line">KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */</span><br><span class="line"></span><br><span class="line">Chain DOCKER (1 references)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line"></span><br><span class="line">Chain DOCKER-ISOLATION (1 references)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">RETURN     all  --  anywhere             anywhere</span><br><span class="line"></span><br><span class="line">Chain KUBE-FIREWALL (2 references)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">DROP       all  --  anywhere             anywhere             /* kubernetes firewall <span class="keyword">for</span> dropping marked packets */ mark match 0x8000/0x8000</span><br><span class="line"></span><br><span class="line">Chain KUBE-FORWARD (1 references)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             /* kubernetes forwarding rules */ mark match 0x4000/0x4000</span><br><span class="line">ACCEPT     all  --  10.254.0.0/16        anywhere             /* kubernetes forwarding conntrack pod <span class="built_in">source</span> rule */ ctstate RELATED,ESTABLISHED</span><br><span class="line">ACCEPT     all  --  anywhere             10.254.0.0/16        /* kubernetes forwarding conntrack pod destination rule */ ctstate RELATED,ESTABLISHED</span><br><span class="line"></span><br><span class="line">Chain KUBE-SERVICES (2 references)</span><br><span class="line">target     prot opt <span class="built_in">source</span>               destination</span><br><span class="line">Copy</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;K8S-Flannel&quot;&gt;&lt;a href=&quot;#K8S-Flannel&quot; class=&quot;headerlink&quot; title=&quot;K8S Flannel&quot;&gt;&lt;/a&gt;K8S Flannel&lt;/h4&gt;&lt;p&gt;Flannel 的网络个人理解为，flannel接管了所有k8s n
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="network" scheme="https://www.xiemx.com/tags/network/"/>
    
      <category term="flannel" scheme="https://www.xiemx.com/tags/flannel/"/>
    
  </entry>
  
  <entry>
    <title>k8s pause container</title>
    <link href="https://www.xiemx.com//2020/01/20/k8s-pause-container/"/>
    <id>https://www.xiemx.com//2020/01/20/k8s-pause-container/</id>
    <published>2020-01-20T04:01:52.000Z</published>
    <updated>2020-01-21T09:02:31.436Z</updated>
    
    <content type="html"><![CDATA[<h3 id="pause-container"><a href="#pause-container" class="headerlink" title="pause container"></a>pause container</h3><p>Pause容器，也被称为infra容器，kubelet 启动是可以通过参数指定image<code>--pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0</code> </p><p>在Unix系统中，PID为1的进程为init进程，即所有进程的父进程。它会维护一张进程表，不断地检查进程状态，来管理子进程。init 不会响应系统信号，可以防止init进程被误杀。</p><p>pause容器的架构图：</p><p><img src="/images/pause_container.png" alt="The pause container"></p><p>kubernetes中的pause容器的功能：</p><ul><li>创建命名空间基础，给予后续容器使用</li><li>创建init进程作为父进程来接管后续容器的进程，保证进程安全和回收</li></ul><hr><p>参考：<a href="https://www.ianlewis.org/en/almighty-pause-container" target="_blank" rel="noopener">https://www.ianlewis.org/en/almighty-pause-container</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;pause-container&quot;&gt;&lt;a href=&quot;#pause-container&quot; class=&quot;headerlink&quot; title=&quot;pause container&quot;&gt;&lt;/a&gt;pause container&lt;/h3&gt;&lt;p&gt;Pause容器，也被称为infra容
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="docker" scheme="https://www.xiemx.com/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>Nginx URI参数%xx字符解码</title>
    <link href="https://www.xiemx.com//2020/01/09/nginx-decode-uri/"/>
    <id>https://www.xiemx.com//2020/01/09/nginx-decode-uri/</id>
    <published>2020-01-09T06:32:04.000Z</published>
    <updated>2020-01-09T06:32:20.152Z</updated>
    
    <content type="html"><![CDATA[<h4 id="Nginx-URI参数-xx字符解码"><a href="#Nginx-URI参数-xx字符解码" class="headerlink" title="Nginx URI参数%xx字符解码"></a>Nginx URI参数%xx字符解码</h4><p>对URI参数值中的<code>%XX</code>这样的编码序列进行解码，可以使用第三方 <code>ngx_set_misc</code> 模块提供的 <code>set_unescape_uri</code> 指令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">    location /decode &#123;</span><br><span class="line">        set_unescape_uri <span class="variable">$name</span> <span class="variable">$arg_name</span>;</span><br><span class="line">        set_unescape_uri <span class="variable">$class</span> <span class="variable">$arg_class</span>;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"name: <span class="variable">$name</span>"</span>;</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"class: <span class="variable">$class</span>"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    location /<span class="built_in">test</span> &#123;</span><br><span class="line">      <span class="built_in">echo</span> <span class="string">"name: <span class="variable">$arg_name</span>"</span>;</span><br><span class="line">      <span class="built_in">echo</span> <span class="string">"class: <span class="variable">$arg_class</span>"</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">$ curl <span class="string">'http://localhost/test?name=hello%20xiemx&amp;class=1'</span></span><br><span class="line">name: hello%20xiemx</span><br><span class="line">class: 1</span><br><span class="line"></span><br><span class="line">$ curl <span class="string">'http://localhost/decode?name=hello%20xiemx&amp;class=1'</span></span><br><span class="line">name: hello xiemx</span><br><span class="line">class: 1</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;Nginx-URI参数-xx字符解码&quot;&gt;&lt;a href=&quot;#Nginx-URI参数-xx字符解码&quot; class=&quot;headerlink&quot; title=&quot;Nginx URI参数%xx字符解码&quot;&gt;&lt;/a&gt;Nginx URI参数%xx字符解码&lt;/h4&gt;&lt;p&gt;对URI参数
      
    
    </summary>
    
    
      <category term="nginx" scheme="https://www.xiemx.com/categories/nginx/"/>
    
    
      <category term="webserver" scheme="https://www.xiemx.com/tags/webserver/"/>
    
      <category term="nginx" scheme="https://www.xiemx.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>如何在K8S环境中抓POD的包</title>
    <link href="https://www.xiemx.com//2019/12/12/k8s-tcpdump/"/>
    <id>https://www.xiemx.com//2019/12/12/k8s-tcpdump/</id>
    <published>2019-12-12T02:01:04.000Z</published>
    <updated>2019-12-12T07:05:08.737Z</updated>
    
    <content type="html"><![CDATA[<h3 id="如何在K8S环境中抓POD的包"><a href="#如何在K8S环境中抓POD的包" class="headerlink" title="如何在K8S环境中抓POD的包"></a>如何在K8S环境中抓POD的包</h3><ol><li><p>kubectl get pod -o wide 获取pod所在的node信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">➜  Documents kubectl get pod -o wide </span><br><span class="line">NAME                                                 READY   STATUS             RESTARTS   AGE   IP             NODE                                              NOMINATED NODE</span><br><span class="line">internal-nginx-ingress-controller-7fdf7f457d-bd59z   1/1     Running            0          42m   10.200.1.83    ip-10-200-1-202.ap-northeast-1.compute.internal   &lt;none&gt;</span><br><span class="line"></span><br><span class="line">2. kubectl describe pod/podname 获取pod的containid</span><br><span class="line">```shell</span><br><span class="line">➜  Documents k get pod -o jsonpath='&#123;.status.containerStatuses[*].containerID&#125;' internal-nginx-ingress-controller-7fdf7f457d-bd59z</span><br><span class="line">docker://ae9a6df60584e797e56cc64d0df02e64d7731a0d852026fab0a76c920c608cbe</span><br></pre></td></tr></table></figure></li><li><p>登陆node节点，找到container查看eth0网卡的ID</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[ec2-user@ip-10-200-1-202 net]$ docker exec -it ae9a6df60584e797e56cc64d0df02e64d7731a0d852026fab0a76c920c608cbe cat /sys/class/net/eth0/iflink</span><br><span class="line">88</span><br></pre></td></tr></table></figure></li><li><p>宿主机上查询对应ID的网卡设备号</p><figure class="highlight llvm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">[ec<span class="number">2</span>-user<span class="title">@ip-10-200-1-202</span> net]$ cd /sys/class/net<span class="comment">; for i in $(ls);do echo $i ;grep 88 $i/ifindex;done</span></span><br><span class="line"><span class="comment">eni0143b083c86</span></span><br><span class="line"><span class="comment">eni154a5470c40</span></span><br><span class="line"><span class="comment">eni1c162323f07</span></span><br><span class="line"><span class="comment">eni1d3e2ba2ce1</span></span><br><span class="line"><span class="comment">eni3fbceb3330b</span></span><br><span class="line"><span class="comment">eni457702aeb41</span></span><br><span class="line"><span class="comment">eni45f360a240e</span></span><br><span class="line"><span class="comment">eni50431e3a94f</span></span><br><span class="line"><span class="comment">eni619e29d4bac</span></span><br><span class="line"><span class="comment">eni66339821adf</span></span><br><span class="line"><span class="comment">eni6fe679d6356</span></span><br><span class="line"><span class="comment">eni79708a78f8b</span></span><br><span class="line"><span class="comment">eni7cc26b0b7d2</span></span><br><span class="line"><span class="comment">eni855ca0ba49b</span></span><br><span class="line"><span class="comment">eni8799376f27c</span></span><br><span class="line"><span class="comment">eni90208382a7b</span></span><br><span class="line"><span class="comment">eni909411bbf11</span></span><br><span class="line"><span class="comment">eni94c3d2bb833</span></span><br><span class="line"><span class="comment">enia14f5f7c3e9</span></span><br><span class="line"><span class="comment">enib70b44b2399</span></span><br><span class="line"><span class="comment">enic2ad9523b38 ###容器所属网卡</span></span><br><span class="line"><span class="comment">88</span></span><br><span class="line"><span class="comment">enid60e48c6616</span></span><br><span class="line"><span class="comment">enid8f13b5dd06</span></span><br><span class="line"><span class="comment">enida858799e91</span></span><br><span class="line"><span class="comment">enieee4f7696a1</span></span><br><span class="line"><span class="comment">enif0d5e81d420</span></span><br><span class="line"><span class="comment">eth0</span></span><br><span class="line"><span class="comment">eth1</span></span><br><span class="line"><span class="comment">lo</span></span><br></pre></td></tr></table></figure></li><li><p>tcpdump 抓包即可</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">➜  ssh-keys git:(master) ✗ ssh -F ~/.matrix/jp/ssh.aux.config 10.200.1.202 -l ec2-user "sudo tcpdump -vvv -i enic2ad9523b38 tcp port 80 -w -" | wireshark -k -i -</span><br><span class="line">Warning: Permanently added '10.200.1.4' (ECDSA) to the list of known hosts.</span><br><span class="line">Warning: Permanently added '10.200.1.202' (ECDSA) to the list of known hosts.</span><br><span class="line">tcpdump: listening on eni86f5b593a42, link-type EN10MB (Ethernet), capture size 262144 bytes</span><br><span class="line">tcpdump: pcap_loop: The interface went down</span><br><span class="line">7408 packets captured</span><br><span class="line">7408 packets received by filter</span><br><span class="line">0 packets dropped by kernel</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;如何在K8S环境中抓POD的包&quot;&gt;&lt;a href=&quot;#如何在K8S环境中抓POD的包&quot; class=&quot;headerlink&quot; title=&quot;如何在K8S环境中抓POD的包&quot;&gt;&lt;/a&gt;如何在K8S环境中抓POD的包&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;kubectl g
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="network" scheme="https://www.xiemx.com/tags/network/"/>
    
      <category term="linux" scheme="https://www.xiemx.com/tags/linux/"/>
    
      <category term="tcpdump" scheme="https://www.xiemx.com/tags/tcpdump/"/>
    
  </entry>
  
  <entry>
    <title>nginx remote_port为空</title>
    <link href="https://www.xiemx.com//2019/12/12/nginx-remote-port-is-null/"/>
    <id>https://www.xiemx.com//2019/12/12/nginx-remote-port-is-null/</id>
    <published>2019-12-12T02:01:04.000Z</published>
    <updated>2019-12-12T07:06:52.916Z</updated>
    
    <content type="html"><![CDATA[<h3 id="nginx-remote-port为空"><a href="#nginx-remote-port为空" class="headerlink" title="nginx remote_port为空"></a>nginx remote_port为空</h3><h4 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h4><p>由于网安要求记录用户请求来源端口到日志中，因此为了实现这个需求在log_format中增加了”ngx_remote_port: $remote_port”字段(如下)， 但实际日志系统中收录到的日志<code>ngx_remote_port:&quot;&quot;</code>为空</p><figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">log_format json '&#123; <span class="string">"time"</span>: <span class="string">"<span class="variable">$time_iso8601</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_true_client_ip"</span>: <span class="string">"<span class="variable">$http_true_client_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_x_real_ip"</span>: <span class="string">"<span class="variable">$http_x_real_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_cdn_src_ip"</span>: <span class="string">"<span class="variable">$http_cdn_src_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_geo_location_ip"</span>: <span class="string">"<span class="variable">$client_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_remote_addr"</span>: <span class="string">"<span class="variable">$remote_addr</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_remote_port"</span>: <span class="string">"<span class="variable">$remote_port</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_x_user_site_proxy"</span>: <span class="string">"<span class="variable">$http_x_user_site_proxy</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_x_forwarded_for"</span>: <span class="string">"<span class="variable">$http_x_forwarded_for</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_host"</span>: <span class="string">"<span class="variable">$host</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_http_user_agent"</span>: <span class="string">"<span class="variable">$http_user_agent</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_body_bytes_sent"</span>: <span class="string">"<span class="variable">$body_bytes_sent</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_request_time"</span>: <span class="string">"<span class="variable">$request_time</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_upstream_response_time"</span>: <span class="string">"<span class="variable">$upstream_response_time</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_upstream_connect_time"</span>: <span class="string">"<span class="variable">$upstream_connect_time</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_upstream_header_time:"</span>: <span class="string">"<span class="variable">$upstream_header_time</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_upstream_addr"</span>: <span class="string">"<span class="variable">$upstream_addr</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_upstream_content_length"</span>: <span class="string">"<span class="variable">$sent_http_content_length</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_status_code"</span>: <span class="string">"<span class="variable">$status</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_scheme"</span>: <span class="string">"<span class="variable">$scheme</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_request_method"</span>: <span class="string">"<span class="variable">$request_method</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_request_uri"</span>: <span class="string">"<span class="variable">$request_uri</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_request"</span>: <span class="string">"<span class="variable">$request</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_http_referrer"</span>: <span class="string">"<span class="variable">$http_referer</span>"</span>  &#125;';</span><br></pre></td></tr></table></figure><h4 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h4><p>由于$remote_port这个变量是nginx核心模块提供的，因此猜测是由第三方模块再次操作导致为空，经过测试发现通过proxy进来的请求remote_port为空，<br>而直接访问本地nginx的请求都能够正确获取port信息，对于以上2中情况的对比<br>怀疑是由于经过proxy之类的组建request header中有x-forworder-for的头，从而触发了realip 模块（这个怀疑没有具体验证），解决方案就是使用realip模块提供的变量’realip_remote_port’来记录来源port, 修改log_format</p><figure class="highlight julia"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">log_format json '&#123; <span class="string">"time"</span>: <span class="string">"<span class="variable">$time_iso8601</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_true_client_ip"</span>: <span class="string">"<span class="variable">$http_true_client_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_x_real_ip"</span>: <span class="string">"<span class="variable">$http_x_real_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_cdn_src_ip"</span>: <span class="string">"<span class="variable">$http_cdn_src_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_geo_location_ip"</span>: <span class="string">"<span class="variable">$client_ip</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_remote_addr"</span>: <span class="string">"<span class="variable">$remote_addr</span>"</span>, '</span><br><span class="line">                    '<span class="string">"ngx_remote_port"</span>: <span class="string">"<span class="variable">$remote_port</span>"</span>, '</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;nginx-remote-port为空&quot;&gt;&lt;a href=&quot;#nginx-remote-port为空&quot; class=&quot;headerlink&quot; title=&quot;nginx remote_port为空&quot;&gt;&lt;/a&gt;nginx remote_port为空&lt;/h3&gt;&lt;h4 i
      
    
    </summary>
    
    
      <category term="nginx" scheme="https://www.xiemx.com/categories/nginx/"/>
    
    
      <category term="webserver" scheme="https://www.xiemx.com/tags/webserver/"/>
    
      <category term="nginx" scheme="https://www.xiemx.com/tags/nginx/"/>
    
  </entry>
  
  <entry>
    <title>k8s ingress-nginx动态balance实现解析</title>
    <link href="https://www.xiemx.com//2019/09/16/k8s-ingress-nginx/"/>
    <id>https://www.xiemx.com//2019/09/16/k8s-ingress-nginx/</id>
    <published>2019-09-15T23:09:52.000Z</published>
    <updated>2019-10-21T06:57:42.989Z</updated>
    
    <content type="html"><![CDATA[<p>只节选了比较关键的代码，删除了比较多的干扰项。纯属个人理解！！！</p><h4 id="1-初始化balancer-init-worker-，使用balancer-balance-动态获取"><a href="#1-初始化balancer-init-worker-，使用balancer-balance-动态获取" class="headerlink" title="1. 初始化balancer.init_worker()，使用balancer.balance()动态获取"></a>1. 初始化balancer.init_worker()，使用balancer.balance()动态获取</h4><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">http &#123;</span><br><span class="line">        lua_package_path <span class="string">"/etc/nginx/lua/?.lua;/etc/nginx/lua/vendor/?.lua;/usr/local/lib/lua/?.lua;;"</span>;</span><br><span class="line">        init_by_lua_block &#123;</span><br><span class="line">                ok, res = <span class="built_in">pcall</span>(<span class="built_in">require</span>, <span class="string">"configuration"</span>)</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        init_worker_by_lua_block &#123;</span><br><span class="line">                balancer.init_worker()  #####创建定时任务 ngx.timer.every(BACKENDS_SYNC_INTERVAL, sync_backends)</span><br><span class="line">        &#125;</span><br><span class="line">     </span><br><span class="line">###upstream configure</span><br><span class="line">upstream upstream_balancer &#123;</span><br><span class="line">server <span class="number">0.0</span><span class="number">.0</span><span class="number">.1</span>; # placeholder</span><br><span class="line"></span><br><span class="line">balancer_by_lua_block &#123;</span><br><span class="line">balancer.balance()</span><br><span class="line">&#125;</span><br><span class="line">keepalive <span class="number">32</span>;</span><br><span class="line">keepalive_timeout  <span class="number">60</span>s;</span><br><span class="line">keepalive_requests <span class="number">100</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-获取backend信息，balancer-init-worker"><a href="#2-获取backend信息，balancer-init-worker" class="headerlink" title="2. 获取backend信息，balancer.init_worker()"></a>2. 获取backend信息，balancer.init_worker()</h4><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">####https://sourcegraph.com/github.com/kubernetes/ingress-nginx@dd0fe4b458cc5520f25eb8bba25bbe6f0c72ee98/-/blob/rootfs/etc/nginx/lua/balancer.lua?utm_source=share#L223</span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> configuration = <span class="built_in">require</span>(<span class="string">"configuration"</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.init_worker</span><span class="params">()</span></span></span><br><span class="line">  sync_backends() <span class="comment">-- when worker starts, sync backends without delay</span></span><br><span class="line">  <span class="keyword">local</span> _, err = ngx.timer.every(BACKENDS_SYNC_INTERVAL, sync_backends)</span><br><span class="line">  <span class="keyword">if</span> err <span class="keyword">then</span></span><br><span class="line">    ngx.<span class="built_in">log</span>(ngx.ERR, <span class="built_in">string</span>.<span class="built_in">format</span>(<span class="string">"error when setting up timer.every for sync_backends: %s"</span>, <span class="built_in">tostring</span>(err)))</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">sync_backends</span><span class="params">()</span></span></span><br><span class="line">  <span class="keyword">local</span> backends_data = configuration.get_backends_data()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> new_backends, err = cjson.decode(backends_data)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> balancers_to_keep = &#123;&#125;</span><br><span class="line">  <span class="keyword">for</span> _, new_backend <span class="keyword">in</span> <span class="built_in">ipairs</span>(new_backends) <span class="keyword">do</span></span><br><span class="line">    sync_backend(new_backend)</span><br><span class="line">    balancers_to_keep[new_backend.name] = balancers[new_backend.name]</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">####https://sourcegraph.com/github.com/kubernetes/ingress-nginx@dd0fe4b458cc5520f25eb8bba25bbe6f0c72ee98/-/blob/rootfs/etc/nginx/lua/configuration.lua?utm_source=share#L10:<span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> configuration_data = ngx.shared.configuration_data</span><br><span class="line"><span class="keyword">local</span> certificate_data = ngx.shared.certificate_data</span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> _M = &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.get_backends_data</span><span class="params">()</span></span></span><br><span class="line">  <span class="keyword">return</span> configuration_data:get(<span class="string">"backends"</span>)</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.call</span><span class="params">()</span></span></span><br><span class="line">  <span class="keyword">if</span> ngx.var.request_method ~= <span class="string">"POST"</span> <span class="keyword">and</span> ngx.var.request_method ~= <span class="string">"GET"</span> <span class="keyword">then</span></span><br><span class="line">    ngx.<span class="built_in">status</span> = ngx.HTTP_BAD_REQUEST</span><br><span class="line">    ngx.<span class="built_in">print</span>(<span class="string">"Only POST and GET requests are allowed!"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ngx.var.request_uri == <span class="string">"/configuration/servers"</span> <span class="keyword">then</span></span><br><span class="line">    handle_servers()</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ngx.var.request_uri == <span class="string">"/configuration/general"</span> <span class="keyword">then</span></span><br><span class="line">    handle_general()</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ngx.var.uri == <span class="string">"/configuration/certs"</span> <span class="keyword">then</span></span><br><span class="line">    handle_certs()</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> ngx.var.request_uri ~= <span class="string">"/configuration/backends"</span> <span class="keyword">then</span> ####只接受以上<span class="number">4</span>类型URL</span><br><span class="line">    ngx.<span class="built_in">status</span> = ngx.HTTP_NOT_FOUND</span><br><span class="line">    ngx.<span class="built_in">print</span>(<span class="string">"Not found!"</span>)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> backends = fetch_request_body()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> success, err = configuration_data:set(<span class="string">"backends"</span>, backends)</span><br><span class="line"></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">### fetch_request_body()，从此函数可以看出此函数是一个外部调用，可以得出原始的数据来源为外部触发的POST，可以查询Call()函数的引用位置</span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">fetch_request_body</span><span class="params">()</span></span></span><br><span class="line">  ngx.req.read_body() ###防止ngx.req.get_body_data()返回<span class="literal">nil</span>,显示执行一下</span><br><span class="line">  <span class="keyword">local</span> body = ngx.req.get_body_data()</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> body <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">local</span> file_name = ngx.req.get_body_file() ###读取cache file</span><br><span class="line"></span><br><span class="line">    <span class="keyword">local</span> file = <span class="built_in">io</span>.<span class="built_in">open</span>(file_name, <span class="string">"rb"</span>)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> file <span class="keyword">then</span></span><br><span class="line">      <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">    body = file:<span class="built_in">read</span>(<span class="string">"*all"</span>)</span><br><span class="line">    file:<span class="built_in">close</span>()</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> body</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">####nginx.conf 查看nginx配置文件中显示调用call()函数的位置为当前server切url /configuration 符合函数要求，在查找外部调用的代码（基本可以定位为控制器的逻辑控制）</span></span><br><span class="line">       <span class="built_in"> server </span>&#123;</span><br><span class="line">                listen unix:/tmp/nginx-status-server.sock;</span><br><span class="line">                <span class="builtin-name">set</span> <span class="variable">$proxy_upstream_name</span> <span class="string">"internal"</span>;</span><br><span class="line"></span><br><span class="line">                keepalive_timeout 0;</span><br><span class="line">                gzip off;</span><br><span class="line"></span><br><span class="line">                access_log off;</span><br><span class="line"></span><br><span class="line">                location /configuration &#123;</span><br><span class="line">                        # this should be equals <span class="keyword">to</span> configuration_data dict</span><br><span class="line">                        client_max_body_size                    10m;</span><br><span class="line">                        client_body_buffer_size                 10m;</span><br><span class="line">                        proxy_buffering                         off;</span><br><span class="line"></span><br><span class="line">                        content_by_lua_block &#123;</span><br><span class="line">                                configuration.call()</span><br><span class="line">                        &#125;</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure><h4 id="3-通过上面的信息检索，在Ingress中监听pod变化信息，动态调用-configuration-backends-函数为configureBackends"><a href="#3-通过上面的信息检索，在Ingress中监听pod变化信息，动态调用-configuration-backends-函数为configureBackends" class="headerlink" title="3. 通过上面的信息检索，在Ingress中监听pod变化信息，动态调用/configuration/backends, 函数为configureBackends()"></a>3. 通过上面的信息检索，在Ingress中监听pod变化信息，动态调用/configuration/backends, 函数为configureBackends()</h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">####https:<span class="comment">//github.com/kubernetes/ingress-nginx/blob/ce3e3d51c397ff6a0cd6731cc64360ecdb69ea54/internal/ingress/controller/nginx.go#L982</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">configureBackends</span><span class="params">(rawBackends []*ingress.Backend)</span> <span class="title">error</span></span> &#123;</span><br><span class="line">backends := <span class="built_in">make</span>([]*ingress.Backend, <span class="built_in">len</span>(rawBackends))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, backend := <span class="keyword">range</span> rawBackends &#123;</span><br><span class="line"><span class="keyword">var</span> service *apiv1.Service</span><br><span class="line"><span class="keyword">if</span> backend.Service != <span class="literal">nil</span> &#123;</span><br><span class="line">service = &amp;apiv1.Service&#123;Spec: backend.Service.Spec&#125;</span><br><span class="line">&#125;</span><br><span class="line">luaBackend := &amp;ingress.Backend&#123;</span><br><span class="line">Name:                 backend.Name,</span><br><span class="line">Port:                 backend.Port,</span><br><span class="line">SSLPassthrough:       backend.SSLPassthrough,</span><br><span class="line">SessionAffinity:      backend.SessionAffinity,</span><br><span class="line">UpstreamHashBy:       backend.UpstreamHashBy,</span><br><span class="line">LoadBalancing:        backend.LoadBalancing,</span><br><span class="line">Service:              service,</span><br><span class="line">NoServer:             backend.NoServer,</span><br><span class="line">TrafficShapingPolicy: backend.TrafficShapingPolicy,</span><br><span class="line">AlternativeBackends:  backend.AlternativeBackends,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> endpoints []ingress.Endpoint</span><br><span class="line"><span class="keyword">for</span> _, endpoint := <span class="keyword">range</span> backend.Endpoints &#123;</span><br><span class="line">endpoints = <span class="built_in">append</span>(endpoints, ingress.Endpoint&#123;</span><br><span class="line">Address: endpoint.Address,</span><br><span class="line">Port:    endpoint.Port,</span><br><span class="line">&#125;)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">luaBackend.Endpoints = endpoints</span><br><span class="line">backends[i] = luaBackend</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">statusCode, _, err := nginx.NewPostStatusRequest(<span class="string">"/configuration/backends"</span>, <span class="string">"application/json"</span>, backends) ####backends 为request.body,却内容为IP/PORT，以下给出了backend的<span class="keyword">struct</span></span><br><span class="line"><span class="keyword">if</span> err != <span class="literal">nil</span> &#123;</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> statusCode != http.StatusCreated &#123;</span><br><span class="line"><span class="keyword">return</span> fmt.Errorf(<span class="string">"unexpected error code: %d"</span>, statusCode)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">####Backend <span class="keyword">struct</span></span><br><span class="line"><span class="keyword">type</span> Backend <span class="keyword">struct</span> &#123;</span><br><span class="line">Name    <span class="keyword">string</span>             <span class="string">`json:"name"`</span></span><br><span class="line">Service *apiv1.Service     <span class="string">`json:"service,omitempty"`</span></span><br><span class="line">Port    intstr.IntOrString <span class="string">`json:"port"`</span></span><br><span class="line">SecureCACert resolver.AuthSSLCert <span class="string">`json:"secureCACert"`</span></span><br><span class="line">SSLPassthrough <span class="keyword">bool</span> <span class="string">`json:"sslPassthrough"`</span></span><br><span class="line">Endpoints []Endpoint <span class="string">`json:"endpoints,omitempty"`</span></span><br><span class="line">SessionAffinity SessionAffinityConfig <span class="string">`json:"sessionAffinityConfig"`</span></span><br><span class="line">UpstreamHashBy UpstreamHashByConfig <span class="string">`json:"upstreamHashByConfig,omitempty"`</span></span><br><span class="line">LoadBalancing <span class="keyword">string</span> <span class="string">`json:"load-balance,omitempty"`</span></span><br><span class="line">NoServer <span class="keyword">bool</span> <span class="string">`json:"noServer"`</span></span><br><span class="line">TrafficShapingPolicy TrafficShapingPolicy <span class="string">`json:"trafficShapingPolicy,omitempty"`</span></span><br><span class="line">AlternativeBackends []<span class="keyword">string</span> <span class="string">`json:"alternativeBackends,omitempty"`</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-ngx-balancer-set-current-peer-设置backend信息"><a href="#4-ngx-balancer-set-current-peer-设置backend信息" class="headerlink" title="4. ngx_balancer.set_current_peer()设置backend信息"></a>4. ngx_balancer.set_current_peer()设置backend信息</h4><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">####https://sourcegraph.com/github.com/kubernetes/ingress-nginx@dd0fe4b458cc5520f25eb8bba25bbe6f0c72ee98/-/blob/rootfs/etc/nginx/lua/balancer.lua?utm_source=share#L232:<span class="number">13</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">_M.balance</span><span class="params">()</span></span></span><br><span class="line">  <span class="keyword">local</span> balancer = get_balancer()</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> balancer <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> peer = balancer:balance()</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> peer <span class="keyword">then</span></span><br><span class="line">    ngx.<span class="built_in">log</span>(ngx.WARN, <span class="string">"no peer was returned, balancer: "</span> .. balancer.name)</span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  ngx_balancer.set_more_tries(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> ok, err = ngx_balancer.set_current_peer(peer) ####设置server信息</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> ok <span class="keyword">then</span></span><br><span class="line">    ngx.<span class="built_in">log</span>(ngx.ERR, <span class="built_in">string</span>.<span class="built_in">format</span>(<span class="string">"error while setting current upstream peer %s: %s"</span>, peer, err))</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">local</span> <span class="function"><span class="keyword">function</span> <span class="title">get_balancer</span><span class="params">()</span></span></span><br><span class="line">  <span class="keyword">if</span> ngx.ctx.balancer <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> ngx.ctx.balancer</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> backend_name = ngx.var.proxy_upstream_name ###获取当前request上下文中共享的变量proxy_upstream_name</span><br><span class="line"></span><br><span class="line">  <span class="keyword">local</span> balancer = balancers[backend_name] ###获取balancers信息由sync_backend()函数定时轮询</span><br><span class="line">  <span class="keyword">if</span> <span class="keyword">not</span> balancer <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> route_to_alternative_balancer(balancer) <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">local</span> alternative_backend_name = balancer.alternative_backends[<span class="number">1</span>]</span><br><span class="line">    ngx.var.proxy_alternative_upstream_name = alternative_backend_name</span><br><span class="line"></span><br><span class="line">    balancer = balancers[alternative_backend_name]</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">  ngx.ctx.balancer = balancer</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> balancer</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">###nginx.conf</span></span><br><span class="line"><span class="attribute">set</span> <span class="variable">$proxy_upstream_name</span>    <span class="string">"dev-dev-auto-deploy-5000"</span>;</span><br><span class="line"><span class="attribute">set</span> <span class="variable">$proxy_host</span>             <span class="variable">$proxy_upstream_name</span>;</span><br><span class="line"></span><br><span class="line"><span class="attribute">proxy_pass</span> http://upstream_balancer;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;只节选了比较关键的代码，删除了比较多的干扰项。纯属个人理解！！！&lt;/p&gt;
&lt;h4 id=&quot;1-初始化balancer-init-worker-，使用balancer-balance-动态获取&quot;&gt;&lt;a href=&quot;#1-初始化balancer-init-worker-，使用b
      
    
    </summary>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/categories/k8s/"/>
    
    
      <category term="k8s" scheme="https://www.xiemx.com/tags/k8s/"/>
    
      <category term="ingress" scheme="https://www.xiemx.com/tags/ingress/"/>
    
  </entry>
  
  <entry>
    <title>PostgreSQL查看复制状态</title>
    <link href="https://www.xiemx.com//2019/07/08/postgresql-replica-status/"/>
    <id>https://www.xiemx.com//2019/07/08/postgresql-replica-status/</id>
    <published>2019-07-08T03:07:36.000Z</published>
    <updated>2019-10-19T09:40:34.388Z</updated>
    
    <content type="html"><![CDATA[<h4 id="postgresql查看复制状态，master上执行"><a href="#postgresql查看复制状态，master上执行" class="headerlink" title="postgresql查看复制状态，master上执行"></a>postgresql查看复制状态，master上执行</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#select * from pg_stat_replication; </span></span><br><span class="line">postgres=<span class="comment"># select * from pg_stat_replication;</span></span><br><span class="line">-[ RECORD 1 ]<span class="comment">----+------------------------------</span></span><br><span class="line">pid              | 13321</span><br><span class="line">usesysid         | 17019</span><br><span class="line">usename          | replication</span><br><span class="line">application_name | walreceiver</span><br><span class="line">client_addr      | 10.0.0.81</span><br><span class="line">client_hostname  | </span><br><span class="line">client_port      | 42809</span><br><span class="line">backend_start    | 2016-08-11 10:57:35.856289+08</span><br><span class="line">backend_xmin     | </span><br><span class="line">state            | streaming <span class="comment">--同步状态</span></span><br><span class="line">sent_location    | 1/E0CE9750</span><br><span class="line">write_location   | 1/E0CE9750</span><br><span class="line">flush_location   | 1/E0CE9750</span><br><span class="line">replay_location  | 1/E0CE9750</span><br><span class="line">sync_priority    | 0</span><br><span class="line">sync_state       | async  <span class="comment">--同步模式</span></span><br><span class="line"></span><br><span class="line">state: 同步状态</span><br><span class="line">    streaming : 同步</span><br><span class="line">    startup : 连接中</span><br><span class="line">    catchup: 同步中</span><br><span class="line"></span><br><span class="line">sync_state: 同步模式.</span><br><span class="line">    async : 异步</span><br><span class="line">    sync : 同步</span><br><span class="line">    potential: 虽然现在是异步,但有可能提升到同步</span><br></pre></td></tr></table></figure><h4 id="查看复制的延迟有多少，字节单位，master上执行"><a href="#查看复制的延迟有多少，字节单位，master上执行" class="headerlink" title="查看复制的延迟有多少，字节单位，master上执行"></a>查看复制的延迟有多少，字节单位，master上执行</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#select pg_xlog_location_diff(sent_location, replay_location) from pg_stat_replication; </span></span><br><span class="line"></span><br><span class="line">posrgresql=<span class="comment"># select pg_xlog_location_diff(sent_location, replay_location) from pg_stat_replication; </span></span><br><span class="line"> pg_xlog_location_diff </span><br><span class="line"><span class="comment">-----------------------</span></span><br><span class="line">                      0</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><h4 id="slave上查看sql滞后时间"><a href="#slave上查看sql滞后时间" class="headerlink" title="slave上查看sql滞后时间"></a>slave上查看sql滞后时间</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">CASE</span> <span class="keyword">WHEN</span> pg_last_xlog_receive_location() = pg_last_xlog_replay_location()</span><br><span class="line">    <span class="keyword">THEN</span> <span class="number">0</span></span><br><span class="line">    <span class="keyword">ELSE</span> <span class="keyword">EXTRACT</span> (EPOCH <span class="keyword">FROM</span> <span class="keyword">now</span>() - pg_last_xact_replay_timestamp())</span><br><span class="line">    <span class="keyword">END</span> <span class="keyword">AS</span> log_delay;</span><br><span class="line"></span><br><span class="line">postgres=<span class="comment"># SELECT CASE WHEN pg_last_xlog_receive_location() = pg_last_xlog_replay_location()</span></span><br><span class="line">postgres-<span class="comment">#     THEN 0</span></span><br><span class="line">postgres-<span class="comment">#     ELSE EXTRACT (EPOCH FROM now() - pg_last_xact_replay_timestamp())</span></span><br><span class="line">postgres-<span class="comment">#     END AS log_delay;</span></span><br><span class="line"> log_delay</span><br><span class="line"><span class="comment">-----------</span></span><br><span class="line">         0</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><h4 id="slave上查看是否处于recovery模式"><a href="#slave上查看是否处于recovery模式" class="headerlink" title="slave上查看是否处于recovery模式"></a>slave上查看是否处于recovery模式</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">select</span> pg_is_in_recovery();</span><br><span class="line">postgres=<span class="comment"># select pg_is_in_recovery();</span></span><br><span class="line"> pg_is_in_recovery</span><br><span class="line"><span class="comment">-------------------</span></span><br><span class="line"> t</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><h4 id="slave上查看最新的reploy时间戳"><a href="#slave上查看最新的reploy时间戳" class="headerlink" title="slave上查看最新的reploy时间戳"></a>slave上查看最新的reploy时间戳</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#select pg_last_xact_replay_timestamp();</span></span><br><span class="line">postgres=<span class="comment"># select pg_last_xact_replay_timestamp();</span></span><br><span class="line"> pg_last_xact_replay_timestamp</span><br><span class="line"><span class="comment">-------------------------------</span></span><br><span class="line"> 2019-07-08 03:01:33.854131+00</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure><h4 id="slave上查看最新的reploy位置"><a href="#slave上查看最新的reploy位置" class="headerlink" title="slave上查看最新的reploy位置"></a>slave上查看最新的reploy位置</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#select pg_last_xlog_replay_location();</span></span><br><span class="line">postgres=<span class="comment"># select pg_last_xlog_replay_location();</span></span><br><span class="line"> pg_last_xlog_replay_location</span><br><span class="line"><span class="comment">------------------------------</span></span><br><span class="line"> 220C/56EB4C10</span><br><span class="line">(1 row)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;postgresql查看复制状态，master上执行&quot;&gt;&lt;a href=&quot;#postgresql查看复制状态，master上执行&quot; class=&quot;headerlink&quot; title=&quot;postgresql查看复制状态，master上执行&quot;&gt;&lt;/a&gt;postgres
      
    
    </summary>
    
    
      <category term="postgresql" scheme="https://www.xiemx.com/categories/postgresql/"/>
    
    
      <category term="database" scheme="https://www.xiemx.com/tags/database/"/>
    
      <category term="postgresql" scheme="https://www.xiemx.com/tags/postgresql/"/>
    
  </entry>
  
  <entry>
    <title>http cache</title>
    <link href="https://www.xiemx.com//2019/05/13/http-cache/"/>
    <id>https://www.xiemx.com//2019/05/13/http-cache/</id>
    <published>2019-05-13T03:05:02.000Z</published>
    <updated>2019-10-21T06:57:42.935Z</updated>
    
    <content type="html"><![CDATA[<h4 id="cache流程图"><a href="#cache流程图" class="headerlink" title="cache流程图"></a><strong>cache流程图</strong></h4><p><img src="/images/image.png" alt="img"></p><h3 id="“no-cache”和“no-store”"><a href="#“no-cache”和“no-store”" class="headerlink" title="“no-cache”和“no-store”"></a>“no-cache”和“no-store”</h3><p>“no-cache”表示必须先与服务器确认返回的响应是否发生了变化，然后才能使用该响应来满足后续对同一网址的请求。 因此，如果存在合适的验证令牌 (ETag)，no-cache 会发起往返通信来验证缓存的响应，但如果资源未发生变化，则可避免下载。</p><p>“no-store”禁止浏览器以及所有中间缓存存储任何版本的返回响应，例如，包含个人隐私数据或银行业务数据的响应。 每次用户请求该资产时，都会向服务器发送请求，并下载完整的响应。</p><h3 id="“public”与-“private”"><a href="#“public”与-“private”" class="headerlink" title="“public”与 “private”"></a>“public”与 “private”</h3><p>“public”则即使它有关联的 HTTP 身份验证，甚至响应状态代码通常无法缓存，也可以缓存响应。 大多数情况下，“public”不是必需的，因为明确的缓存信息（例如“max-age”）已表示响应是可以缓存的。</p><p>“private”浏览器可以缓存响应，不允许任何中间缓存对其进行缓存。 例如，用户的浏览器可以缓存包含用户私人信息的 HTML 网页，但 CDN 却不能缓存。</p><h3 id="“max-age”"><a href="#“max-age”" class="headerlink" title="“max-age”"></a>“max-age”</h3><p>指令指定从请求的时间开始，允许提取的响应被重用的最长时间（单位：秒）。 例如，“max-age=60”表示可在接下来的 60 秒缓存和重用响应。</p><h2 id="通过-ETag-验证缓存的响应"><a href="#通过-ETag-验证缓存的响应" class="headerlink" title="通过 ETag 验证缓存的响应"></a>通过 ETag 验证缓存的响应</h2><p>在首次请求资源时服务器生成并返回”ETag” http请求头(通常是文件内容的哈希值或某个其他指纹)。 当120 秒后，浏览器又对该资源发起了新的请求。 首先，浏览器会检查本地缓存并找到之前的响应。如果发现缓存超过max-age, 浏览器将发起一个带有”If-None-Match”的http请求。 如果Etag相同，则返回304，使用本地缓存。</p><p><img src="/images/http-cache-control.png" alt="HTTP Cache-Control 示例"></p><p>参考： <a href="https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching" target="_blank" rel="noopener">https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/http-caching</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;cache流程图&quot;&gt;&lt;a href=&quot;#cache流程图&quot; class=&quot;headerlink&quot; title=&quot;cache流程图&quot;&gt;&lt;/a&gt;&lt;strong&gt;cache流程图&lt;/strong&gt;&lt;/h4&gt;&lt;p&gt;&lt;img src=&quot;/images/image.png&quot; 
      
    
    </summary>
    
    
      <category term="http" scheme="https://www.xiemx.com/categories/http/"/>
    
    
      <category term="http" scheme="https://www.xiemx.com/tags/http/"/>
    
      <category term="cache" scheme="https://www.xiemx.com/tags/cache/"/>
    
  </entry>
  
  <entry>
    <title>Mysqldump error</title>
    <link href="https://www.xiemx.com//2019/05/06/mysqldump-error/"/>
    <id>https://www.xiemx.com//2019/05/06/mysqldump-error/</id>
    <published>2019-05-06T03:05:56.000Z</published>
    <updated>2019-10-19T10:22:28.240Z</updated>
    
    <content type="html"><![CDATA[<h3 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h3><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@FCHK-instance ~]# mysqldump <span class="comment">--host rm-xxxxxxxxxxx.mysql.rds.aliyuncs.com -u xxxx -p --databases visa &gt; hk.sql</span></span><br><span class="line">Enter password:</span><br><span class="line"><span class="literal">Warning</span>: A partial dump from a server that has GTIDs will by <span class="keyword">default</span> include the GTIDs <span class="keyword">of</span> <span class="keyword">all</span> transactions, even those that changed suppressed parts <span class="keyword">of</span> the database. <span class="keyword">If</span> you don<span class="symbol">'t</span> want <span class="keyword">to</span> restore GTIDs, pass <span class="comment">--set-gtid-purged=OFF. To make a complete dump, pass --all-databases --triggers --routines --events.</span></span><br><span class="line">mysqldump: Couldn<span class="symbol">'t</span> execute <span class="symbol">'SELECT</span> COLUMN_NAME,                       JSON_EXTRACT(HISTOGRAM, '$.<span class="string">"number-of-buckets-specified"</span>')                FROM information_schema.COLUMN_STATISTICS                WHERE SCHEMA_NAME = <span class="symbol">'visa</span>' <span class="keyword">AND</span> TABLE_NAME = <span class="symbol">'admin</span>';': Unknown table <span class="symbol">'column_statistics</span>' <span class="keyword">in</span> information_schema (<span class="number">1109</span></span><br></pre></td></tr></table></figure><h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">[root@FCHK-instance ~]# mysql <span class="comment">--version</span></span><br><span class="line">mysql  Ver <span class="number">8.0</span><span class="number">.11</span> <span class="keyword">for</span> Linux <span class="keyword">on</span> x86_64 (MySQL Community <span class="keyword">Server</span> - GPL)</span><br><span class="line"></span><br><span class="line">可能是由于mysqldump <span class="number">8</span>中默认启用（COLUMN_STATISTICS）</span><br><span class="line"></span><br><span class="line">官方文档解释</span><br><span class="line">Mysql <span class="number">8.0</span> The INFORMATION_SCHEMA COLUMN_STATISTICS <span class="keyword">Table</span></span><br><span class="line">https://dev.mysql.com/doc/refman/<span class="number">8.0</span>/en/<span class="keyword">column</span>-<span class="keyword">statistics</span>-<span class="keyword">table</span>.html</span><br></pre></td></tr></table></figure><h3 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h3><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@FCHK-instance ~]# mysqldump <span class="comment">--host rm-xxxxxxxxxx2.mysql.rds.aliyuncs.com -u xxxx -p --databases visa --column-statistics=0 &gt; hk.sql</span></span><br><span class="line">Enter password:</span><br><span class="line"><span class="literal">Warning</span>: A partial dump from a server that has GTIDs will by <span class="keyword">default</span> include the GTIDs <span class="keyword">of</span> <span class="keyword">all</span> transactions, even those that changed suppressed parts <span class="keyword">of</span> the database. <span class="keyword">If</span> you don<span class="symbol">'t</span> want <span class="keyword">to</span> restore GTIDs, pass <span class="comment">--set-gtid-purged=OFF. To make a complete dump, pass --all-databases --triggers --routines --events.</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;现象&quot;&gt;&lt;a href=&quot;#现象&quot; class=&quot;headerlink&quot; title=&quot;现象&quot;&gt;&lt;/a&gt;现象&lt;/h3&gt;&lt;figure class=&quot;highlight vhdl&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span c
      
    
    </summary>
    
    
      <category term="mysql" scheme="https://www.xiemx.com/categories/mysql/"/>
    
    
      <category term="mysql" scheme="https://www.xiemx.com/tags/mysql/"/>
    
      <category term="debug" scheme="https://www.xiemx.com/tags/debug/"/>
    
      <category term="database" scheme="https://www.xiemx.com/tags/database/"/>
    
  </entry>
  
</feed>
